{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTCSqsLKpNUm"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lix_hvw6pPfW"
      },
      "source": [
        "The Spaceship Titanic is a Machine Learning competition currently running on Kaggle with the participation of more than 2,000 teams.\n",
        "\n",
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RFhhtgMEM5L"
      },
      "source": [
        "## Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9ZN17VrET-b"
      },
      "source": [
        "Welcome to the year 2912, where your data science skills are needed to solve a cosmic mystery. We've received a transmission from four lightyears away and things aren't looking good.\n",
        "\n",
        "The Spaceship Titanic was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars.\n",
        "\n",
        "While rounding Alpha Centauri en route to its first destination—the torrid 55 Cancri E—the unwary Spaceship Titanic collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!\n",
        "\n",
        "To help rescue crews and retrieve the lost passengers, you are challenged to predict which passengers were transported by the anomaly using records recovered from the spaceship’s damaged computer system.\n",
        "\n",
        "Help save them and change history!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HIEqtVydu7fj"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vQB8et9rEpq"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QscZZ7V1p-hE"
      },
      "source": [
        "The dataset provides 12 input variables that are a mixture of categorical, ordinal, boolean and numerical data types:\n",
        "\n",
        "1. PassengerId\n",
        "2. HomePlanet\n",
        "3. CryoSleep\n",
        "4. Destination\n",
        "5. Age\n",
        "6. VIP\n",
        "7. RoomService\n",
        "8. FoodCourt\n",
        "9. ShoppingMall\n",
        "10. Spa\n",
        "11. VRDeck\n",
        "12. Name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKQt8K-Iqq7z"
      },
      "source": [
        "This is a binary classification problem where the task is to predict whether a passenger was transported to an alternate dimension. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIGPTYpVreAH"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S5YbcZQU7xfz"
      },
      "outputs": [],
      "source": [
        "# Suppressing Warnings:\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkRwXuzOZ_ci",
        "outputId": "0b738d73-3b08-4c71-ef22-1cc08a40d2ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## mount your Google drive\n",
        "# 1) click on the link\n",
        "# 2) sign in\n",
        "# 3) copy the provided code\n",
        "# 4) paste it in the text box bellow\n",
        "# 5) click the folder icon at the right\n",
        "# 6) verify your drive is mounted\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrYC0mfKFkh7"
      },
      "source": [
        "Clone the GRAPE repository at first because the dataset to be used is already there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSDPe5O9FOt0",
        "outputId": "6f799b5e-9ab5-495c-f30d-fec325cb732f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "fatal: destination path 'grape' already exists and is not an empty directory.\n",
            "Cloning grape in your Drive\n",
            "/content/drive/MyDrive/grape\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Get the library from our BDS research Group\n",
        "# copy the path from your drive\n",
        "PATH = '/content/drive/u/1/folders/1--2pl_taR8wZpcFAvbQNWaQen1afSZQF'\n",
        "\n",
        "# check if 'grape' already exists\n",
        "if os.path.exists(PATH):\n",
        "    print('grape directory already exists')\n",
        "else:\n",
        "    %cd /content/drive/MyDrive/\n",
        "    !git clone https://github.com/UL-BDS/grape.git \n",
        "    print('Cloning grape in your Drive')\n",
        "\n",
        "# change directory to 'grape'\n",
        "%cd /content/drive/MyDrive/grape/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpHKEV4avk8j"
      },
      "source": [
        "### Train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NjzisImfFrNS"
      },
      "outputs": [],
      "source": [
        "train_file = 'datasets/spaceshipTitanic_train.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Iu2IFnaMtrH6",
        "outputId": "35406a47-7e50-440e-8a4b-4cc48d76f770"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId HomePlanet  CryoSleep    Destination  Age    VIP  RoomService  \\\n",
              "0            0      Earth      False    55 Cancri e   22  False            0   \n",
              "1            1       Mars       True    TRAPPIST-1e   61  False            0   \n",
              "2            2       Mars       True    TRAPPIST-1e    5  False            0   \n",
              "3            3      Earth      False    55 Cancri e   14  False          653   \n",
              "4            4      Earth      False  PSO J318.5-22    2  False            0   \n",
              "\n",
              "   FoodCourt  ShoppingMall  Spa  VRDeck            Name  Transported  \n",
              "0        833           381    0      12   Miranda Pratt         True  \n",
              "1          0             0    0       0    Isaac Werner         True  \n",
              "2          0             0    0       0  Elisha Rosario         True  \n",
              "3          0             4    0       0    Deshawn Hall        False  \n",
              "4          0             0    0       0  Justice Archer         True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1806a836-492b-43d3-a0b7-79de0713e7d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>HomePlanet</th>\n",
              "      <th>CryoSleep</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Age</th>\n",
              "      <th>VIP</th>\n",
              "      <th>RoomService</th>\n",
              "      <th>FoodCourt</th>\n",
              "      <th>ShoppingMall</th>\n",
              "      <th>Spa</th>\n",
              "      <th>VRDeck</th>\n",
              "      <th>Name</th>\n",
              "      <th>Transported</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Earth</td>\n",
              "      <td>False</td>\n",
              "      <td>55 Cancri e</td>\n",
              "      <td>22</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>833</td>\n",
              "      <td>381</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>Miranda Pratt</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Mars</td>\n",
              "      <td>True</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>61</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Isaac Werner</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Mars</td>\n",
              "      <td>True</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Elisha Rosario</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Earth</td>\n",
              "      <td>False</td>\n",
              "      <td>55 Cancri e</td>\n",
              "      <td>14</td>\n",
              "      <td>False</td>\n",
              "      <td>653</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Deshawn Hall</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Earth</td>\n",
              "      <td>False</td>\n",
              "      <td>PSO J318.5-22</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Justice Archer</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1806a836-492b-43d3-a0b7-79de0713e7d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1806a836-492b-43d3-a0b7-79de0713e7d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1806a836-492b-43d3-a0b7-79de0713e7d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# load train set\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/grape/datasets/spaceshipTitanic_train.csv')\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "SBQDVfs4vQNP",
        "outputId": "bf018887-34c6-4e20-c313-8eeeabf86c1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       PassengerId          Age  RoomService     FoodCourt  ShoppingMall  \\\n",
              "count  2000.000000  2000.000000  2000.000000   2000.000000   2000.000000   \n",
              "mean    999.500000    28.555500   213.460500    497.902500    166.237000   \n",
              "std     577.494589    14.629112   615.762402   1763.257082    509.568841   \n",
              "min       0.000000     0.000000     0.000000      0.000000      0.000000   \n",
              "25%     499.750000    20.000000     0.000000      0.000000      0.000000   \n",
              "50%     999.500000    26.000000     0.000000      0.000000      0.000000   \n",
              "75%    1499.250000    37.000000    32.000000     61.250000     23.000000   \n",
              "max    1999.000000    79.000000  6899.000000  27723.000000  10424.000000   \n",
              "\n",
              "                Spa        VRDeck  \n",
              "count   2000.000000   2000.000000  \n",
              "mean     342.252000    269.211000  \n",
              "std     1236.474773   1021.074852  \n",
              "min        0.000000      0.000000  \n",
              "25%        0.000000      0.000000  \n",
              "50%        0.000000      0.000000  \n",
              "75%       67.250000     37.000000  \n",
              "max    18572.000000  14485.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a42d3c3-d6f0-4f9d-af22-0c7b64954785\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Age</th>\n",
              "      <th>RoomService</th>\n",
              "      <th>FoodCourt</th>\n",
              "      <th>ShoppingMall</th>\n",
              "      <th>Spa</th>\n",
              "      <th>VRDeck</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>999.500000</td>\n",
              "      <td>28.555500</td>\n",
              "      <td>213.460500</td>\n",
              "      <td>497.902500</td>\n",
              "      <td>166.237000</td>\n",
              "      <td>342.252000</td>\n",
              "      <td>269.211000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>577.494589</td>\n",
              "      <td>14.629112</td>\n",
              "      <td>615.762402</td>\n",
              "      <td>1763.257082</td>\n",
              "      <td>509.568841</td>\n",
              "      <td>1236.474773</td>\n",
              "      <td>1021.074852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>499.750000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>999.500000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1499.250000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>61.250000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>67.250000</td>\n",
              "      <td>37.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1999.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>6899.000000</td>\n",
              "      <td>27723.000000</td>\n",
              "      <td>10424.000000</td>\n",
              "      <td>18572.000000</td>\n",
              "      <td>14485.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a42d3c3-d6f0-4f9d-af22-0c7b64954785')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a42d3c3-d6f0-4f9d-af22-0c7b64954785 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a42d3c3-d6f0-4f9d-af22-0c7b64954785');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6NtyRPmvx4sq"
      },
      "outputs": [],
      "source": [
        "X_train = df_train.copy()\n",
        "# warning: cannot drop it more than once\n",
        "X_train.drop(['Transported'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iV-mN0J2xMdk"
      },
      "outputs": [],
      "source": [
        "# class labels\n",
        "import numpy as np\n",
        "l, _ = X_train.shape\n",
        "\n",
        "y_train = np.zeros([l,], dtype=bool)\n",
        "\n",
        "for i in range(l):\n",
        "  y_train[i] = df_train['Transported'].iloc[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te26rlaBjLXd",
        "outputId": "f56d3f78-cff7-44b2-aab9-79064d3e252c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True  True  True False  True]\n"
          ]
        }
      ],
      "source": [
        "#y_train.head()\n",
        "print(y_train[0:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwAxKV7nvpZ8"
      },
      "source": [
        "### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1IzzBvGUvtkI"
      },
      "outputs": [],
      "source": [
        "test_file = 'datasets/spaceshipTitanic_test.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DbAn0FpFvPhO",
        "outputId": "f955597f-9487-4836-e5e6-0f9d43657feb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId HomePlanet  CryoSleep  Destination  Age    VIP  RoomService  \\\n",
              "0         2000       Mars      False  TRAPPIST-1e   54  False          676   \n",
              "1         2001       Mars      False  TRAPPIST-1e   43  False          336   \n",
              "2         2002     Europa      False  55 Cancri e   33  False           77   \n",
              "3         2003      Earth       True  55 Cancri e   30  False            0   \n",
              "4         2004     Europa      False  TRAPPIST-1e   31  False            0   \n",
              "\n",
              "   FoodCourt  ShoppingMall   Spa  VRDeck            Name  \n",
              "0          0           231   379       0     Dawson Knox  \n",
              "1         11           796    15       0  Jaylee Navarro  \n",
              "2       2381             0  3656     150      Dario Hart  \n",
              "3          0             0     0       0    Alden Parker  \n",
              "4         53             0  2963    1017      Gina Frank  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e685d630-31d3-4aa3-a7ea-c2e9527c4b2b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>HomePlanet</th>\n",
              "      <th>CryoSleep</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Age</th>\n",
              "      <th>VIP</th>\n",
              "      <th>RoomService</th>\n",
              "      <th>FoodCourt</th>\n",
              "      <th>ShoppingMall</th>\n",
              "      <th>Spa</th>\n",
              "      <th>VRDeck</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>Mars</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>54</td>\n",
              "      <td>False</td>\n",
              "      <td>676</td>\n",
              "      <td>0</td>\n",
              "      <td>231</td>\n",
              "      <td>379</td>\n",
              "      <td>0</td>\n",
              "      <td>Dawson Knox</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>Mars</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>43</td>\n",
              "      <td>False</td>\n",
              "      <td>336</td>\n",
              "      <td>11</td>\n",
              "      <td>796</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>Jaylee Navarro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002</td>\n",
              "      <td>Europa</td>\n",
              "      <td>False</td>\n",
              "      <td>55 Cancri e</td>\n",
              "      <td>33</td>\n",
              "      <td>False</td>\n",
              "      <td>77</td>\n",
              "      <td>2381</td>\n",
              "      <td>0</td>\n",
              "      <td>3656</td>\n",
              "      <td>150</td>\n",
              "      <td>Dario Hart</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003</td>\n",
              "      <td>Earth</td>\n",
              "      <td>True</td>\n",
              "      <td>55 Cancri e</td>\n",
              "      <td>30</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Alden Parker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004</td>\n",
              "      <td>Europa</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>31</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>2963</td>\n",
              "      <td>1017</td>\n",
              "      <td>Gina Frank</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e685d630-31d3-4aa3-a7ea-c2e9527c4b2b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e685d630-31d3-4aa3-a7ea-c2e9527c4b2b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e685d630-31d3-4aa3-a7ea-c2e9527c4b2b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# load test set\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/grape/datasets/spaceshipTitanic_test.csv')\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_Q0uvjTzvfLU",
        "outputId": "01706ae4-2bd8-4c99-93fe-ecfecd5b9f17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       PassengerId          Age   RoomService     FoodCourt  ShoppingMall  \\\n",
              "count  4923.000000  4923.000000   4923.000000   4923.000000   4923.000000   \n",
              "mean   4461.000000    29.028235    231.206175    473.335568    184.646354   \n",
              "std    1421.292018    14.466997    696.138873   1634.705363    677.528376   \n",
              "min    2000.000000     0.000000      0.000000      0.000000      0.000000   \n",
              "25%    3230.500000    19.000000      0.000000      0.000000      0.000000   \n",
              "50%    4461.000000    27.000000      0.000000      0.000000      0.000000   \n",
              "75%    5691.500000    38.000000     59.000000     84.000000     31.000000   \n",
              "max    6922.000000    79.000000  14327.000000  29813.000000  23492.000000   \n",
              "\n",
              "                Spa        VRDeck  \n",
              "count   4923.000000   4923.000000  \n",
              "mean     308.407678    317.807434  \n",
              "std     1126.346091   1164.989135  \n",
              "min        0.000000      0.000000  \n",
              "25%        0.000000      0.000000  \n",
              "50%        0.000000      0.000000  \n",
              "75%       63.000000     59.500000  \n",
              "max    22408.000000  20336.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-405be20b-c4a9-40d8-a924-d370a727d0fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Age</th>\n",
              "      <th>RoomService</th>\n",
              "      <th>FoodCourt</th>\n",
              "      <th>ShoppingMall</th>\n",
              "      <th>Spa</th>\n",
              "      <th>VRDeck</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4923.000000</td>\n",
              "      <td>4923.000000</td>\n",
              "      <td>4923.000000</td>\n",
              "      <td>4923.000000</td>\n",
              "      <td>4923.000000</td>\n",
              "      <td>4923.000000</td>\n",
              "      <td>4923.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4461.000000</td>\n",
              "      <td>29.028235</td>\n",
              "      <td>231.206175</td>\n",
              "      <td>473.335568</td>\n",
              "      <td>184.646354</td>\n",
              "      <td>308.407678</td>\n",
              "      <td>317.807434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1421.292018</td>\n",
              "      <td>14.466997</td>\n",
              "      <td>696.138873</td>\n",
              "      <td>1634.705363</td>\n",
              "      <td>677.528376</td>\n",
              "      <td>1126.346091</td>\n",
              "      <td>1164.989135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3230.500000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4461.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5691.500000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>59.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6922.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>14327.000000</td>\n",
              "      <td>29813.000000</td>\n",
              "      <td>23492.000000</td>\n",
              "      <td>22408.000000</td>\n",
              "      <td>20336.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-405be20b-c4a9-40d8-a924-d370a727d0fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-405be20b-c4a9-40d8-a924-d370a727d0fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-405be20b-c4a9-40d8-a924-d370a727d0fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df_test.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uR_Ie5No4eDV",
        "outputId": "161b0ce7-ec3a-4867-b69d-b43a3b6daee5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      PassengerId HomePlanet  CryoSleep    Destination  Age    VIP  \\\n",
              "0            2000       Mars      False    TRAPPIST-1e   54  False   \n",
              "1            2001       Mars      False    TRAPPIST-1e   43  False   \n",
              "2            2002     Europa      False    55 Cancri e   33  False   \n",
              "3            2003      Earth       True    55 Cancri e   30  False   \n",
              "4            2004     Europa      False    TRAPPIST-1e   31  False   \n",
              "...           ...        ...        ...            ...  ...    ...   \n",
              "4918         6918      Earth       True  PSO J318.5-22   46  False   \n",
              "4919         6919     Europa       True    TRAPPIST-1e   15  False   \n",
              "4920         6920      Earth      False    55 Cancri e   20  False   \n",
              "4921         6921      Earth      False  PSO J318.5-22   42  False   \n",
              "4922         6922     Europa      False    TRAPPIST-1e   29  False   \n",
              "\n",
              "      RoomService  FoodCourt  ShoppingMall   Spa  VRDeck             Name  \n",
              "0             676          0           231   379       0      Dawson Knox  \n",
              "1             336         11           796    15       0   Jaylee Navarro  \n",
              "2              77       2381             0  3656     150       Dario Hart  \n",
              "3               0          0             0     0       0     Alden Parker  \n",
              "4               0         53             0  2963    1017       Gina Frank  \n",
              "...           ...        ...           ...   ...     ...              ...  \n",
              "4918            0          0             0     0       0     Lamar Knight  \n",
              "4919            0          0             0     0       0   Yadira Pittman  \n",
              "4920            0          0             0   335     957   Maliyah Morgan  \n",
              "4921            0        168             0   113     461  Brynlee Gilbert  \n",
              "4922            0       2509             0    16     698   Micaela Nelson  \n",
              "\n",
              "[4923 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dcb5f44f-b1be-4d17-9720-e50382f1ecc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>HomePlanet</th>\n",
              "      <th>CryoSleep</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Age</th>\n",
              "      <th>VIP</th>\n",
              "      <th>RoomService</th>\n",
              "      <th>FoodCourt</th>\n",
              "      <th>ShoppingMall</th>\n",
              "      <th>Spa</th>\n",
              "      <th>VRDeck</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>Mars</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>54</td>\n",
              "      <td>False</td>\n",
              "      <td>676</td>\n",
              "      <td>0</td>\n",
              "      <td>231</td>\n",
              "      <td>379</td>\n",
              "      <td>0</td>\n",
              "      <td>Dawson Knox</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>Mars</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>43</td>\n",
              "      <td>False</td>\n",
              "      <td>336</td>\n",
              "      <td>11</td>\n",
              "      <td>796</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>Jaylee Navarro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002</td>\n",
              "      <td>Europa</td>\n",
              "      <td>False</td>\n",
              "      <td>55 Cancri e</td>\n",
              "      <td>33</td>\n",
              "      <td>False</td>\n",
              "      <td>77</td>\n",
              "      <td>2381</td>\n",
              "      <td>0</td>\n",
              "      <td>3656</td>\n",
              "      <td>150</td>\n",
              "      <td>Dario Hart</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003</td>\n",
              "      <td>Earth</td>\n",
              "      <td>True</td>\n",
              "      <td>55 Cancri e</td>\n",
              "      <td>30</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Alden Parker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004</td>\n",
              "      <td>Europa</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>31</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>2963</td>\n",
              "      <td>1017</td>\n",
              "      <td>Gina Frank</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4918</th>\n",
              "      <td>6918</td>\n",
              "      <td>Earth</td>\n",
              "      <td>True</td>\n",
              "      <td>PSO J318.5-22</td>\n",
              "      <td>46</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Lamar Knight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4919</th>\n",
              "      <td>6919</td>\n",
              "      <td>Europa</td>\n",
              "      <td>True</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>15</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yadira Pittman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4920</th>\n",
              "      <td>6920</td>\n",
              "      <td>Earth</td>\n",
              "      <td>False</td>\n",
              "      <td>55 Cancri e</td>\n",
              "      <td>20</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>335</td>\n",
              "      <td>957</td>\n",
              "      <td>Maliyah Morgan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4921</th>\n",
              "      <td>6921</td>\n",
              "      <td>Earth</td>\n",
              "      <td>False</td>\n",
              "      <td>PSO J318.5-22</td>\n",
              "      <td>42</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>113</td>\n",
              "      <td>461</td>\n",
              "      <td>Brynlee Gilbert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4922</th>\n",
              "      <td>6922</td>\n",
              "      <td>Europa</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>29</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>2509</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>698</td>\n",
              "      <td>Micaela Nelson</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4923 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcb5f44f-b1be-4d17-9720-e50382f1ecc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dcb5f44f-b1be-4d17-9720-e50382f1ecc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dcb5f44f-b1be-4d17-9720-e50382f1ecc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4Vu3FBV70F-M"
      },
      "outputs": [],
      "source": [
        "X_test = df_test.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xogSlXT5v6GQ"
      },
      "source": [
        "We need to prepare both training and test datasets before working with a Machine Learning method. \n",
        "\n",
        "Consider the following tips:\n",
        "\n",
        "1.   Remove columns that you think does not influence the class label (for example 'PassengerId');\n",
        "2.   Use some encoding method with categorical data.\n",
        "\n",
        "You are free to use any other pre-processing ideas. \n",
        "\n",
        "You could use for instance, one-hot encoding with categorical data, as was shown when we studied the heart disease dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efkMdpZoT3tg"
      },
      "source": [
        "Number of categories on each categorical data:\n",
        "\n",
        "\n",
        "\n",
        "1.   HomePlanet: 3\n",
        "2.   Destination: 3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BFyb8fegNWZP"
      },
      "outputs": [],
      "source": [
        "X_train1 = X_train[['HomePlanet','CryoSleep','Destination','VIP','Age','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']].copy()\n",
        "X_train1['Total Spending']=X_train1['RoomService']+X_train1['FoodCourt']+X_train1['ShoppingMall']+X_train1['Spa']+X_train1['VRDeck']          #creating new feature Total Spending\n",
        "X_train2=X_train1[['HomePlanet','CryoSleep','Destination','VIP','Age','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck','Total Spending']].copy() \n",
        "X_train2['isAdult']=[True if each>18 else False for each in X_train2['Age']]    #creating new feature isAdult\n",
        "X_train2['didTransaction']=[True if each>0 else False for each in X_train2['Total Spending']]    #creating new feature didTransaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zIWHmnw4PAPq",
        "outputId": "2fdbd090-efc0-4b28-d1b2-72b2f0548d0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     HomePlanet  CryoSleep    Destination    VIP  Age  RoomService  FoodCourt  \\\n",
              "0         Earth      False    55 Cancri e  False   22            0        833   \n",
              "1          Mars       True    TRAPPIST-1e  False   61            0          0   \n",
              "2          Mars       True    TRAPPIST-1e  False    5            0          0   \n",
              "3         Earth      False    55 Cancri e  False   14          653          0   \n",
              "4         Earth      False  PSO J318.5-22  False    2            0          0   \n",
              "...         ...        ...            ...    ...  ...          ...        ...   \n",
              "1995      Earth      False    TRAPPIST-1e  False   27          158          0   \n",
              "1996       Mars      False    55 Cancri e  False   51           40        716   \n",
              "1997       Mars      False    TRAPPIST-1e  False   32          689          0   \n",
              "1998       Mars       True    TRAPPIST-1e  False   41            0          0   \n",
              "1999      Earth      False    TRAPPIST-1e  False   19            0         28   \n",
              "\n",
              "      ShoppingMall  Spa  VRDeck  Total Spending  isAdult  didTransaction  \n",
              "0              381    0      12            1226     True            True  \n",
              "1                0    0       0               0     True           False  \n",
              "2                0    0       0               0    False           False  \n",
              "3                4    0       0             657    False            True  \n",
              "4                0    0       0               0    False           False  \n",
              "...            ...  ...     ...             ...      ...             ...  \n",
              "1995          1271    0      71            1500     True            True  \n",
              "1996          1907    0       0            2663     True            True  \n",
              "1997           610    0       0            1299     True            True  \n",
              "1998             0    0       0               0     True           False  \n",
              "1999            62   24    1686            1800     True            True  \n",
              "\n",
              "[2000 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbe86fbf-f780-4038-aee5-e4c003dc2216\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HomePlanet</th>\n",
              "      <th>CryoSleep</th>\n",
              "      <th>Destination</th>\n",
              "      <th>VIP</th>\n",
              "      <th>Age</th>\n",
              "      <th>RoomService</th>\n",
              "      <th>FoodCourt</th>\n",
              "      <th>ShoppingMall</th>\n",
              "      <th>Spa</th>\n",
              "      <th>VRDeck</th>\n",
              "      <th>Total Spending</th>\n",
              "      <th>isAdult</th>\n",
              "      <th>didTransaction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Earth</td>\n",
              "      <td>False</td>\n",
              "      <td>55 Cancri e</td>\n",
              "      <td>False</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>833</td>\n",
              "      <td>381</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1226</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mars</td>\n",
              "      <td>True</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>False</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mars</td>\n",
              "      <td>True</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>False</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Earth</td>\n",
              "      <td>False</td>\n",
              "      <td>55 Cancri e</td>\n",
              "      <td>False</td>\n",
              "      <td>14</td>\n",
              "      <td>653</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>657</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Earth</td>\n",
              "      <td>False</td>\n",
              "      <td>PSO J318.5-22</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>Earth</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>False</td>\n",
              "      <td>27</td>\n",
              "      <td>158</td>\n",
              "      <td>0</td>\n",
              "      <td>1271</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>1500</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>Mars</td>\n",
              "      <td>False</td>\n",
              "      <td>55 Cancri e</td>\n",
              "      <td>False</td>\n",
              "      <td>51</td>\n",
              "      <td>40</td>\n",
              "      <td>716</td>\n",
              "      <td>1907</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2663</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Mars</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>False</td>\n",
              "      <td>32</td>\n",
              "      <td>689</td>\n",
              "      <td>0</td>\n",
              "      <td>610</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1299</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>Mars</td>\n",
              "      <td>True</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>False</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>Earth</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>False</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>62</td>\n",
              "      <td>24</td>\n",
              "      <td>1686</td>\n",
              "      <td>1800</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbe86fbf-f780-4038-aee5-e4c003dc2216')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cbe86fbf-f780-4038-aee5-e4c003dc2216 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cbe86fbf-f780-4038-aee5-e4c003dc2216');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X_train2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3TJtPsbCRHZK"
      },
      "outputs": [],
      "source": [
        "X_test1 = X_test[['HomePlanet','CryoSleep','VIP','Destination','Age','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']].copy()\n",
        "X_test1['Total Spending']=X_test1['RoomService']+X_test1['FoodCourt']+X_test1['ShoppingMall']+X_test1['Spa']+X_test1['VRDeck']\n",
        "X_test2=X_test1[['HomePlanet','CryoSleep','Destination','VIP','Age','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck','Total Spending']].copy()\n",
        "X_test2['isAdult']=[True if each>18 else False for each in X_test2['Age']]\n",
        "X_test2['didTransaction']=[True if each>0 else False for each in X_test2['Total Spending']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NVKufBRWRsqM",
        "outputId": "b2d1cd78-da72-4ab9-cdb1-177db898678e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     HomePlanet  CryoSleep    Destination    VIP  Age  RoomService  FoodCourt  \\\n",
              "0          Mars      False    TRAPPIST-1e  False   54          676          0   \n",
              "1          Mars      False    TRAPPIST-1e  False   43          336         11   \n",
              "2        Europa      False    55 Cancri e  False   33           77       2381   \n",
              "3         Earth       True    55 Cancri e  False   30            0          0   \n",
              "4        Europa      False    TRAPPIST-1e  False   31            0         53   \n",
              "...         ...        ...            ...    ...  ...          ...        ...   \n",
              "4918      Earth       True  PSO J318.5-22  False   46            0          0   \n",
              "4919     Europa       True    TRAPPIST-1e  False   15            0          0   \n",
              "4920      Earth      False    55 Cancri e  False   20            0          0   \n",
              "4921      Earth      False  PSO J318.5-22  False   42            0        168   \n",
              "4922     Europa      False    TRAPPIST-1e  False   29            0       2509   \n",
              "\n",
              "      ShoppingMall   Spa  VRDeck  Total Spending  isAdult  didTransaction  \n",
              "0              231   379       0            1286     True            True  \n",
              "1              796    15       0            1158     True            True  \n",
              "2                0  3656     150            6264     True            True  \n",
              "3                0     0       0               0     True           False  \n",
              "4                0  2963    1017            4033     True            True  \n",
              "...            ...   ...     ...             ...      ...             ...  \n",
              "4918             0     0       0               0     True           False  \n",
              "4919             0     0       0               0    False           False  \n",
              "4920             0   335     957            1292     True            True  \n",
              "4921             0   113     461             742     True            True  \n",
              "4922             0    16     698            3223     True            True  \n",
              "\n",
              "[4923 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e59e92f-5b66-458b-9a0c-42f8b2b65af9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HomePlanet</th>\n",
              "      <th>CryoSleep</th>\n",
              "      <th>Destination</th>\n",
              "      <th>VIP</th>\n",
              "      <th>Age</th>\n",
              "      <th>RoomService</th>\n",
              "      <th>FoodCourt</th>\n",
              "      <th>ShoppingMall</th>\n",
              "      <th>Spa</th>\n",
              "      <th>VRDeck</th>\n",
              "      <th>Total Spending</th>\n",
              "      <th>isAdult</th>\n",
              "      <th>didTransaction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mars</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>False</td>\n",
              "      <td>54</td>\n",
              "      <td>676</td>\n",
              "      <td>0</td>\n",
              "      <td>231</td>\n",
              "      <td>379</td>\n",
              "      <td>0</td>\n",
              "      <td>1286</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mars</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>False</td>\n",
              "      <td>43</td>\n",
              "      <td>336</td>\n",
              "      <td>11</td>\n",
              "      <td>796</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1158</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Europa</td>\n",
              "      <td>False</td>\n",
              "      <td>55 Cancri e</td>\n",
              "      <td>False</td>\n",
              "      <td>33</td>\n",
              "      <td>77</td>\n",
              "      <td>2381</td>\n",
              "      <td>0</td>\n",
              "      <td>3656</td>\n",
              "      <td>150</td>\n",
              "      <td>6264</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Earth</td>\n",
              "      <td>True</td>\n",
              "      <td>55 Cancri e</td>\n",
              "      <td>False</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Europa</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>False</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>2963</td>\n",
              "      <td>1017</td>\n",
              "      <td>4033</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4918</th>\n",
              "      <td>Earth</td>\n",
              "      <td>True</td>\n",
              "      <td>PSO J318.5-22</td>\n",
              "      <td>False</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4919</th>\n",
              "      <td>Europa</td>\n",
              "      <td>True</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>False</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4920</th>\n",
              "      <td>Earth</td>\n",
              "      <td>False</td>\n",
              "      <td>55 Cancri e</td>\n",
              "      <td>False</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>335</td>\n",
              "      <td>957</td>\n",
              "      <td>1292</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4921</th>\n",
              "      <td>Earth</td>\n",
              "      <td>False</td>\n",
              "      <td>PSO J318.5-22</td>\n",
              "      <td>False</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>113</td>\n",
              "      <td>461</td>\n",
              "      <td>742</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4922</th>\n",
              "      <td>Europa</td>\n",
              "      <td>False</td>\n",
              "      <td>TRAPPIST-1e</td>\n",
              "      <td>False</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>2509</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>698</td>\n",
              "      <td>3223</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4923 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e59e92f-5b66-458b-9a0c-42f8b2b65af9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e59e92f-5b66-458b-9a0c-42f8b2b65af9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e59e92f-5b66-458b-9a0c-42f8b2b65af9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "X_test2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPHxsBY-z9cA"
      },
      "source": [
        "Preprocessing Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "e89Z8UTJ0BTf"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "AbaxjmTl0DZE"
      },
      "outputs": [],
      "source": [
        "# Pipeline for numerical values\n",
        "num_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),                              #Declaring StandardScaler encoding for the numerical dataset\n",
        "    (\"scaler\", StandardScaler())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3ATT3pw30GYg"
      },
      "outputs": [],
      "source": [
        "# Pipeline for categorical attributes\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),                       #Declaring one hot encoding for the catagorical dataset\n",
        "    (\"cat_encoder\", OneHotEncoder(sparse=False))  \n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0yqr5SXO0LsF"
      },
      "outputs": [],
      "source": [
        "# Combine the numerical and categorical pipelines\n",
        "\n",
        "num_attribs = [\"Age\",\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\",\"Total Spending\"]                    #All numerical feature to be given to the pipeline\n",
        "cat_attribs = [\"CryoSleep\", \"VIP\",\"HomePlanet\", \"Destination\",\"isAdult\",\"didTransaction\"]                         #All categorical feature to be given to the pipeline\n",
        "                                                                                                                  \n",
        "preprocess_pipeline = ColumnTransformer([                                                                         #Fitting data into the pipeline for scaling and encoding\n",
        "    (\"num\", num_pipeline, num_attribs),\n",
        "    (\"cat\", cat_pipeline, cat_attribs)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R20yI01Z2Tfc",
        "outputId": "f972adb7-0721-4dec-e149-ae15d3b798ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.44822539, -0.34674719,  0.19009214,  0.42156563, -0.27686581,\n",
              "        -0.2519652 , -0.08895365,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
              "         1.        ],\n",
              "       [ 2.21835841, -0.34674719, -0.2824472 , -0.32631229, -0.27686581,\n",
              "        -0.26372046, -0.50352043,  0.        ,  1.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
              "         0.        ,  1.        ,  0.        ,  1.        ,  1.        ,\n",
              "         0.        ],\n",
              "       [-1.61058243, -0.34674719, -0.2824472 , -0.32631229, -0.27686581,\n",
              "        -0.26372046, -0.50352043,  0.        ,  1.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
              "         0.        ,  1.        ,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ],\n",
              "       [-0.99521693,  0.713992  , -0.2824472 , -0.31846055, -0.27686581,\n",
              "        -0.26372046, -0.28135863,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
              "         1.        ],\n",
              "       [-1.81570426, -0.34674719, -0.2824472 , -0.32631229, -0.27686581,\n",
              "        -0.26372046, -0.50352043,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
              "         1.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ],\n",
              "       [ 0.1671401 , -0.04948032, -0.2824472 , -0.2634984 , -0.27686581,\n",
              "         0.88339707, -0.03485032,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
              "         1.        ],\n",
              "       [-0.44822539, -0.34674719, -0.2824472 , -0.32631229, -0.27686581,\n",
              "        -0.26372046, -0.50352043,  0.        ,  1.        ,  1.        ,\n",
              "         0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
              "         0.        ],\n",
              "       [-1.81570426, -0.34674719, -0.2824472 , -0.32631229, -0.27686581,\n",
              "        -0.26372046, -0.50352043,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ,  1.        ,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ],\n",
              "       [ 0.57738377,  0.1828102 , -0.2824472 ,  0.56682276, -0.27524791,\n",
              "        -0.26372046, -0.23875225,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
              "         1.        ],\n",
              "       [-0.58497327, -0.34674719, -0.11793771, -0.32631229,  1.23264066,\n",
              "        -0.05114616,  0.2988996 ,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
              "         1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "X_train2 = preprocess_pipeline.fit_transform(\n",
        "    X_train2[num_attribs + cat_attribs]\n",
        ")\n",
        "X_train2[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMiaRgQR2a01",
        "outputId": "d2bf800b-8356-4ffc-8427-1a03eaf8dd44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.72629481,  0.639009  , -0.28958347,  0.06842275,  0.06268011,\n",
              "        -0.27282634, -0.08009897,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
              "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
              "         1.        ],\n",
              "       [ 0.96586627,  0.1505511 , -0.28285374,  0.90242087, -0.2605216 ,\n",
              "        -0.27282634, -0.12479176,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
              "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
              "         1.        ],\n",
              "       [ 0.2745676 , -0.2215389 ,  1.16709607, -0.27255701,  2.97238335,\n",
              "        -0.14405669,  1.65803143,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
              "         1.        ],\n",
              "       [ 0.067178  , -0.33216025, -0.28958347, -0.27255701, -0.27384035,\n",
              "        -0.27282634, -0.52912181,  0.        ,  1.        ,  1.        ,\n",
              "         0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
              "         0.        ],\n",
              "       [ 0.13630787, -0.33216025, -0.25715843, -0.27255701,  2.35705703,\n",
              "         0.60023185,  0.87905012,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
              "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
              "         1.        ],\n",
              "       [-0.55499081, -0.33216025, -0.28958347, -0.27255701, -0.27384035,\n",
              "        -0.27282634, -0.52912181,  0.        ,  1.        ,  1.        ,\n",
              "         0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
              "         0.        ],\n",
              "       [ 0.34369747, -0.33216025,  2.89785896, -0.27255701,  0.90886479,\n",
              "        -0.27110941,  1.7557969 ,  1.        ,  0.        ,  0.        ,\n",
              "         1.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
              "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
              "         1.        ],\n",
              "       [ 0.96586627, -0.32210376,  0.01264236,  3.37784538,  0.11950678,\n",
              "        -0.21187537,  0.68875662,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
              "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
              "         1.        ],\n",
              "       [ 0.8967364 , -0.33216025, -0.28958347,  0.83452014, -0.27384035,\n",
              "        -0.13890591, -0.21278068,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
              "         1.        ],\n",
              "       [ 0.41282733, -0.33216025, -0.28958347, -0.27255701, -0.27384035,\n",
              "        -0.27282634, -0.52912181,  0.        ,  1.        ,  1.        ,\n",
              "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
              "         0.        ,  1.        ,  0.        ,  1.        ,  1.        ,\n",
              "         0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "X_test2 = preprocess_pipeline.fit_transform(X_test2[num_attribs + cat_attribs])\n",
        "X_test2[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8b5xrjIrqD_"
      },
      "source": [
        "## GRAPE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ05U2S409Dl"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1hw43Oi3lGTCkspQ0ged2bZB8q2EpcPhz\" width=\"150\"/>\n",
        "</div> \n",
        "\n",
        "GRammatical Algorithms in Python for Evolution (GRAPE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be7FcJqpWnJM",
        "outputId": "7be7d7f3-0986-4ee1-cee7-cc9b7ad9a8f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deap==1.3 in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap==1.3) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install deap==1.3 \n",
        "\n",
        "import grape\n",
        "import algorithms\n",
        "\n",
        "from os import path\n",
        "from deap import creator, base, tools\n",
        "import random\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKB9j6fmlFEr"
      },
      "source": [
        "You can import functions to be used with your grammar from [functions.py](https://github.com/UL-BDS/grape/blob/main/functions.py) on GRAPE repository and / or you can define your own functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FMu0U8j-loXC"
      },
      "outputs": [],
      "source": [
        "from functions import add, sub, mul, pdiv, psqrt, plog, neg, and_, or_, not_, less_than_or_equal, greater_than_or_equal,nand_,nor_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wqMTpvYB_jNh"
      },
      "outputs": [],
      "source": [
        "def pexp(a):                                                                    #making functions we want to use in our grammar file\n",
        "  return np.square(a) \n",
        "\n",
        "def pneg(a):\n",
        "  return np.multiply(a,-1)\n",
        "\n",
        "def phalf(a):\n",
        "  return np.multiply(a,0.5)\n",
        "\n",
        "def psin(a):\n",
        "  return np.sin(a)\n",
        "\n",
        "def pcos(a):\n",
        "  return np.cos(a)\n",
        "\n",
        "def ptan(a):\n",
        "  return np.tan(a)\n",
        "\n",
        "def xor_(a, b):\n",
        "    return np.logical_xor(a,b)\n",
        "\n",
        "def mean_(a):\n",
        "    return np.mean(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO948ol2HXAa",
        "outputId": "38e36a3a-283e-4079-e525-1a735dec9d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Banknote.bnf\n",
            " classification_grammer.bnf\n",
            " Dow.bnf\n",
            "'heartDisease (1).bnf'\n",
            " heartDisease.bnf\n",
            " john_Spaceship_Titanic.bnf\n",
            " lawnmower64.bnf\n",
            " Pagie1.bnf\n",
            " parity3.bnf\n",
            " parity4.bnf\n",
            " parity5.bnf\n",
            " parity6.bnf\n",
            " quinticPolynomial.bnf\n",
            " SpaceShip_10_feature_corrected.bnf\n",
            " SpaceShip_10_feature_final.bnf\n",
            " SpaceShip_10_feature_pexp.bnf\n",
            " SpaceShip_10_feature_pneg.bnf\n",
            " SpaceShip_10_feature_ptrigo.bnf\n",
            " SpaceShip_10_feature_test.bnf\n",
            " SpaceShip_11_feature_pneg_nexp_plog.bnf\n",
            " SpaceShip_11_feature_pneg_nexp_plog_psqrt.bnf\n",
            " SpaceShip_11_feature_ptrigo.bnf\n",
            " SpaceShip_11_feature_total.bnf\n",
            " SpaceShip_12_feature_total.bnf\n",
            " SpaceShip_13_feature_corrected.bnf\n",
            " SpaceShip_13_feature_final.bnf\n",
            " SpaceShip_6_feature.bnf\n",
            " SpaceShip_6_feature_nand_nor.bnf\n",
            " SpaceShip_6_feature_pexp.bnf\n",
            " SpaceShip_6_feature_plog.bnf\n",
            " SpaceShip_6_feature_simple.bnf\n",
            " SpaceShip_8_feature_plog.bnf\n",
            " spaceshipTitanic.bnf\n",
            " spambase.bnf\n",
            " test1.bnf\n",
            " test.bnf\n",
            " TwoBoxes.bnf\n",
            " Vladislavleva4.bnf\n"
          ]
        }
      ],
      "source": [
        "ls grammars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7sMFCXtoCyb"
      },
      "source": [
        "'heartDisease.bnf' is a grammar used for another problem just to check if everything is working well.\n",
        "\n",
        "Write your own grammar in a text file and save it in your Drive account.\n",
        "\n",
        "Put the whole address on GRAMMAR_FILE and print to check it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Xc60pTemiIb",
        "outputId": "d4011b4f-13ec-4d7a-b2fd-3eed34bb8457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<log_op> ::= <conditional_branches> | and_(<log_op>,<log_op>) | or_(<log_op>,<log_op>) | not_(<log_op>) | <boolean_feature> | nand_(<log_op>,<log_op>) | nor_(<log_op>,<log_op>) | xor_(<log_op>,<log_op>) | not_(<boolean_feature>)\n",
            "<c>  ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\n",
            "<o> ::= +|-|*\n",
            "<conditional_branches> ::= less_than_or_equal(<num_op>,<num_op>) | greater_than_or_equal(<num_op>, <num_op>)\n",
            "<num_op>   ::= add(<num_op>,<num_op>) | sub(<num_op>,<num_op>) | mul(<num_op>,<num_op>) | pdiv(<num_op>,<num_op>) | <nonboolean_feature> | <nonboolean_feature> <o> <nonboolean_feature> | <nonboolean_feature> | <nonboolean_feature> <o> <nonboolean_feature>\n",
            "<boolean_feature> ::= x[6]|x[7]|x[8]|x[9]|x[10]|x[11]|x[12]|x[13]|x[14]|x[15]|x[16]|x[17]|x[18]|x[19]|x[20]\n",
            "<nonboolean_feature> ::= x[0]|x[1]|x[2]|x[3]|x[4]|x[5]|x[6]|<c><c>.<c><c>|mean_(<nonboolean_feature>)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "GRAMMAR_FILE = 'SpaceShip_13_feature_final.bnf'                                 #importing grammar file from drive\n",
        "f = open(\"grammars/\" + GRAMMAR_FILE, \"r\")                                       #reading and printing the grammar\n",
        "print(f.read())\n",
        "f.close() \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "082ga8rppORi"
      },
      "source": [
        "Run the following cell to put your grammar on the class Grammar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "JEJcyIJKnUoz"
      },
      "outputs": [],
      "source": [
        "\n",
        "BNF_GRAMMAR = grape.Grammar(path.join(\"grammars\", GRAMMAR_FILE))                #utilising the grammar in the grape library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOZl1P-spq3Y"
      },
      "source": [
        "The fitness function is the percentage of outputs wrongly predicted.\n",
        "\n",
        "You can use any other fitness function, but you need to maintain the comma at the end of the returning lines.\n",
        "\n",
        "In this notebook, GRAPE is being used only for minimisation, so the fitness function needs to consider it. If you want to maximise, you also need to change the weights in the toolbox.\n",
        "\n",
        "Moreover, this fitness functions considers the predicted output as True or False. If your grammar allow individuals with other outputs, you need to change the fitness function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Mt5IJHTFprTz"
      },
      "outputs": [],
      "source": [
        "def fitness_eval(individual, points):\n",
        "    \"\"\"\n",
        "    Fitness Function\n",
        "    \"\"\"\n",
        "\n",
        "    x = points[0]\n",
        "    Y = points[1]\n",
        "    \n",
        "    if individual.invalid == True:\n",
        "        return np.NaN,\n",
        "\n",
        "    # Evaluate the expression\n",
        "    try:\n",
        "        pred = eval(individual.phenotype)\n",
        "    except (FloatingPointError, ZeroDivisionError, OverflowError,\n",
        "            MemoryError):\n",
        "        return np.NaN,\n",
        "    assert np.isrealobj(pred)\n",
        "\n",
        "    compare = np.equal(Y,pred)\n",
        "    fitness = 1 - np.mean(compare)\n",
        "   \n",
        "    return fitness,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ5ZUKRYWXRi"
      },
      "source": [
        "To use properly the fitness function above with GRAPE, the features must be in the lines, and the samples must be in the columns, so if your data is not like that, you need to transpose the matrix.\n",
        "\n",
        "Take a look at the print. If you run this cell two times, the matrix will be transposed again and will not work properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPJQ-iGUVutk",
        "outputId": "1da68a7f-a596-4bc7-e3b1-2055a593536f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (X,Y):\t (21, 2000) (2000,)\n",
            "Test (X):\t (21, 4923)\n"
          ]
        }
      ],
      "source": [
        "X_train2 = np.transpose(X_train2)                                               #using transpose to fit the feature in the evaluation function and printing to see the shape\n",
        "X_test2 = np.transpose(X_test2) \n",
        "\n",
        "print('Training (X,Y):\\t', X_train2.shape, y_train.shape)\n",
        "print('Test (X):\\t', X_test2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FZt9KkAqtUS"
      },
      "source": [
        "Set the Grammatical Evolution parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "YHxhHk5uqwFa"
      },
      "outputs": [],
      "source": [
        "\n",
        "POPULATION_SIZE = 10000                                                         #declaring parameters for the GE to take place\n",
        "MAX_GENERATIONS = 500 \n",
        "P_CROSSOVER = 0.85\n",
        "P_MUTATION = 0.05\n",
        "ELITE_SIZE = 1\n",
        "HALL_OFFAME_SIZE = 1\n",
        "\n",
        "TOURNAMENT_SIZE = 10                                                            #using 10 for tournament size\n",
        "RANDOM_SEED = 42                                                                #fixing seed to 42 as constant\n",
        "random.seed(RANDOM_SEED) \n",
        "\n",
        "CODON_CONSUMPTION = 'eager'\n",
        "GENOME_REPRESENTATION = 'list'\n",
        "MAX_GENOME_LENGTH = None\n",
        "\n",
        "MAX_INIT_TREE_DEPTH = 10\n",
        "MIN_INIT_TREE_DEPTH = 5\n",
        "MAX_TREE_DEPTH = 250\n",
        "MAX_WRAPS = 1                                                                   #using max wrap 1 to allow wrapping \n",
        "CODON_SIZE = 255\n",
        "\n",
        "REPORT_ITEMS = ['gen', 'invalid', 'avg', 'std', 'min', 'max', \n",
        "                'best_ind_length', 'avg_length', \n",
        "                'best_ind_nodes', 'avg_nodes', \n",
        "                'best_ind_depth', 'avg_depth', \n",
        "                'avg_used_codons', 'best_ind_used_codons',\n",
        "                'structural_diversity', 'fitness_diversity',\n",
        "                'selection_time', 'generation_time']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfpeXPO_q9By"
      },
      "source": [
        "Create a toolbox."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Mh3DJnexq-oy"
      },
      "outputs": [],
      "source": [
        "toolbox = base.Toolbox()\n",
        "\n",
        "# define a single objective, minimising fitness strategy:\n",
        "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))                     #setting weights to -1 to minimise the fitness score as objective\n",
        " \n",
        "creator.create('Individual', grape.Individual, fitness=creator.FitnessMin)\n",
        "\n",
        "toolbox.register(\"populationCreator\", grape.sensible_initialisation, creator.Individual)        #using sensible initialisation\n",
        "\n",
        "toolbox.register(\"evaluate\", fitness_eval)\n",
        "\n",
        "# Tournament selection:\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=TOURNAMENT_SIZE)      #declaring selTournament for tournament selection\n",
        "\n",
        "# Single-point crossover:\n",
        "toolbox.register(\"mate\", grape.crossover_onepoint)\n",
        "\n",
        "# Flip-int mutation:\n",
        "toolbox.register(\"mutate\", grape.mutation_int_flip_per_codon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "yhCmqPRHrMHJ"
      },
      "outputs": [],
      "source": [
        "# create initial population (generation 0):\n",
        "population = toolbox.populationCreator(pop_size=POPULATION_SIZE, \n",
        "                                           bnf_grammar=BNF_GRAMMAR, \n",
        "                                           min_init_depth=MIN_INIT_TREE_DEPTH,\n",
        "                                           max_init_depth=MAX_INIT_TREE_DEPTH,\n",
        "                                           codon_size=CODON_SIZE,\n",
        "                                           codon_consumption=CODON_CONSUMPTION,\n",
        "                                           genome_representation=GENOME_REPRESENTATION\n",
        "                                            )\n",
        "\n",
        "# define the hall-of-fame object:\n",
        "hof = tools.HallOfFame(HALL_OFFAME_SIZE)\n",
        "\n",
        "# prepare the statistics object:\n",
        "stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
        "stats.register(\"avg\", np.nanmean)\n",
        "stats.register(\"std\", np.nanstd)\n",
        "stats.register(\"min\", np.nanmin)\n",
        "stats.register(\"max\", np.nanmax)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByAiFpujrXmL"
      },
      "source": [
        "Run Grammatical Evolution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si071Z_2raLB",
        "outputId": "832f8045-4cb3-4367-d8b7-3d496361896f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gen = 0 , Best fitness = (0.256,)\n",
            "gen = 1 , Best fitness = (0.256,) , Number of invalids = 4369\n",
            "gen = 2 , Best fitness = (0.24850000000000005,) , Number of invalids = 4883\n",
            "gen = 3 , Best fitness = (0.24850000000000005,) , Number of invalids = 4984\n",
            "gen = 4 , Best fitness = (0.24850000000000005,) , Number of invalids = 5068\n",
            "gen = 5 , Best fitness = (0.24850000000000005,) , Number of invalids = 5057\n",
            "gen = 6 , Best fitness = (0.24850000000000005,) , Number of invalids = 4922\n",
            "gen = 7 , Best fitness = (0.24850000000000005,) , Number of invalids = 5010\n",
            "gen = 8 , Best fitness = (0.24850000000000005,) , Number of invalids = 4986\n",
            "gen = 9 , Best fitness = (0.24850000000000005,) , Number of invalids = 4785\n",
            "gen = 10 , Best fitness = (0.24350000000000005,) , Number of invalids = 4724\n",
            "gen = 11 , Best fitness = (0.24350000000000005,) , Number of invalids = 4683\n",
            "gen = 12 , Best fitness = (0.24350000000000005,) , Number of invalids = 4661\n",
            "gen = 13 , Best fitness = (0.24350000000000005,) , Number of invalids = 4598\n",
            "gen = 14 , Best fitness = (0.24350000000000005,) , Number of invalids = 4644\n",
            "gen = 15 , Best fitness = (0.24350000000000005,) , Number of invalids = 4607\n",
            "gen = 16 , Best fitness = (0.24350000000000005,) , Number of invalids = 4560\n",
            "gen = 17 , Best fitness = (0.24350000000000005,) , Number of invalids = 4405\n",
            "gen = 18 , Best fitness = (0.24350000000000005,) , Number of invalids = 4307\n",
            "gen = 19 , Best fitness = (0.24350000000000005,) , Number of invalids = 4209\n",
            "gen = 20 , Best fitness = (0.24350000000000005,) , Number of invalids = 4178\n",
            "gen = 21 , Best fitness = (0.24350000000000005,) , Number of invalids = 4201\n",
            "gen = 22 , Best fitness = (0.24350000000000005,) , Number of invalids = 4138\n",
            "gen = 23 , Best fitness = (0.24350000000000005,) , Number of invalids = 4122\n",
            "gen = 24 , Best fitness = (0.24350000000000005,) , Number of invalids = 4156\n",
            "gen = 25 , Best fitness = (0.24350000000000005,) , Number of invalids = 4066\n",
            "gen = 26 , Best fitness = (0.24350000000000005,) , Number of invalids = 3962\n",
            "gen = 27 , Best fitness = (0.24350000000000005,) , Number of invalids = 3828\n",
            "gen = 28 , Best fitness = (0.24350000000000005,) , Number of invalids = 3758\n",
            "gen = 29 , Best fitness = (0.24350000000000005,) , Number of invalids = 3687\n",
            "gen = 30 , Best fitness = (0.24350000000000005,) , Number of invalids = 3758\n",
            "gen = 31 , Best fitness = (0.24350000000000005,) , Number of invalids = 3695\n",
            "gen = 32 , Best fitness = (0.24350000000000005,) , Number of invalids = 3567\n",
            "gen = 33 , Best fitness = (0.24350000000000005,) , Number of invalids = 3679\n",
            "gen = 34 , Best fitness = (0.24350000000000005,) , Number of invalids = 3638\n",
            "gen = 35 , Best fitness = (0.24350000000000005,) , Number of invalids = 3594\n",
            "gen = 36 , Best fitness = (0.24350000000000005,) , Number of invalids = 3556\n",
            "gen = 37 , Best fitness = (0.24350000000000005,) , Number of invalids = 3537\n",
            "gen = 38 , Best fitness = (0.24350000000000005,) , Number of invalids = 3524\n",
            "gen = 39 , Best fitness = (0.24350000000000005,) , Number of invalids = 3454\n",
            "gen = 40 , Best fitness = (0.24350000000000005,) , Number of invalids = 3525\n",
            "gen = 41 , Best fitness = (0.24350000000000005,) , Number of invalids = 3439\n",
            "gen = 42 , Best fitness = (0.24350000000000005,) , Number of invalids = 3484\n",
            "gen = 43 , Best fitness = (0.24350000000000005,) , Number of invalids = 3520\n",
            "gen = 44 , Best fitness = (0.24350000000000005,) , Number of invalids = 3532\n",
            "gen = 45 , Best fitness = (0.24350000000000005,) , Number of invalids = 3508\n",
            "gen = 46 , Best fitness = (0.24350000000000005,) , Number of invalids = 3564\n",
            "gen = 47 , Best fitness = (0.24350000000000005,) , Number of invalids = 3618\n",
            "gen = 48 , Best fitness = (0.24350000000000005,) , Number of invalids = 3647\n",
            "gen = 49 , Best fitness = (0.24350000000000005,) , Number of invalids = 3636\n",
            "gen = 50 , Best fitness = (0.24350000000000005,) , Number of invalids = 3653\n",
            "gen = 51 , Best fitness = (0.24350000000000005,) , Number of invalids = 3679\n",
            "gen = 52 , Best fitness = (0.24350000000000005,) , Number of invalids = 3682\n",
            "gen = 53 , Best fitness = (0.24350000000000005,) , Number of invalids = 3709\n",
            "gen = 54 , Best fitness = (0.24350000000000005,) , Number of invalids = 3742\n",
            "gen = 55 , Best fitness = (0.24350000000000005,) , Number of invalids = 3792\n",
            "gen = 56 , Best fitness = (0.24350000000000005,) , Number of invalids = 3804\n",
            "gen = 57 , Best fitness = (0.24350000000000005,) , Number of invalids = 3821\n",
            "gen = 58 , Best fitness = (0.23450000000000004,) , Number of invalids = 3846\n",
            "gen = 59 , Best fitness = (0.23450000000000004,) , Number of invalids = 3859\n",
            "gen = 60 , Best fitness = (0.23450000000000004,) , Number of invalids = 3813\n",
            "gen = 61 , Best fitness = (0.23450000000000004,) , Number of invalids = 3812\n",
            "gen = 62 , Best fitness = (0.23450000000000004,) , Number of invalids = 3795\n",
            "gen = 63 , Best fitness = (0.23450000000000004,) , Number of invalids = 3832\n",
            "gen = 64 , Best fitness = (0.23450000000000004,) , Number of invalids = 3848\n",
            "gen = 65 , Best fitness = (0.23450000000000004,) , Number of invalids = 3837\n",
            "gen = 66 , Best fitness = (0.23450000000000004,) , Number of invalids = 3847\n",
            "gen = 67 , Best fitness = (0.23450000000000004,) , Number of invalids = 3845\n",
            "gen = 68 , Best fitness = (0.23450000000000004,) , Number of invalids = 3783\n",
            "gen = 69 , Best fitness = (0.23450000000000004,) , Number of invalids = 3822\n",
            "gen = 70 , Best fitness = (0.23450000000000004,) , Number of invalids = 3833\n",
            "gen = 71 , Best fitness = (0.23450000000000004,) , Number of invalids = 3827\n",
            "gen = 72 , Best fitness = (0.23450000000000004,) , Number of invalids = 3915\n",
            "gen = 73 , Best fitness = (0.23450000000000004,) , Number of invalids = 3876\n",
            "gen = 74 , Best fitness = (0.23450000000000004,) , Number of invalids = 3847\n",
            "gen = 75 , Best fitness = (0.23450000000000004,) , Number of invalids = 3876\n",
            "gen = 76 , Best fitness = (0.23450000000000004,) , Number of invalids = 3853\n",
            "gen = 77 , Best fitness = (0.23450000000000004,) , Number of invalids = 3856\n",
            "gen = 78 , Best fitness = (0.23450000000000004,) , Number of invalids = 3876\n",
            "gen = 79 , Best fitness = (0.23450000000000004,) , Number of invalids = 3928\n",
            "gen = 80 , Best fitness = (0.23450000000000004,) , Number of invalids = 3948\n",
            "gen = 81 , Best fitness = (0.23450000000000004,) , Number of invalids = 3948\n",
            "gen = 82 , Best fitness = (0.23450000000000004,) , Number of invalids = 3957\n",
            "gen = 83 , Best fitness = (0.23450000000000004,) , Number of invalids = 3926\n",
            "gen = 84 , Best fitness = (0.23450000000000004,) , Number of invalids = 3940\n",
            "gen = 85 , Best fitness = (0.23450000000000004,) , Number of invalids = 3953\n",
            "gen = 86 , Best fitness = (0.23450000000000004,) , Number of invalids = 4007\n",
            "gen = 87 , Best fitness = (0.23450000000000004,) , Number of invalids = 4081\n",
            "gen = 88 , Best fitness = (0.23450000000000004,) , Number of invalids = 4037\n",
            "gen = 89 , Best fitness = (0.23450000000000004,) , Number of invalids = 4146\n",
            "gen = 90 , Best fitness = (0.23450000000000004,) , Number of invalids = 4183\n",
            "gen = 91 , Best fitness = (0.23450000000000004,) , Number of invalids = 4159\n",
            "gen = 92 , Best fitness = (0.23450000000000004,) , Number of invalids = 4144\n",
            "gen = 93 , Best fitness = (0.23450000000000004,) , Number of invalids = 4090\n",
            "gen = 94 , Best fitness = (0.23450000000000004,) , Number of invalids = 4154\n",
            "gen = 95 , Best fitness = (0.23450000000000004,) , Number of invalids = 4136\n",
            "gen = 96 , Best fitness = (0.23450000000000004,) , Number of invalids = 4148\n",
            "gen = 97 , Best fitness = (0.23450000000000004,) , Number of invalids = 4113\n",
            "gen = 98 , Best fitness = (0.23450000000000004,) , Number of invalids = 4219\n",
            "gen = 99 , Best fitness = (0.23450000000000004,) , Number of invalids = 4262\n",
            "gen = 100 , Best fitness = (0.23450000000000004,) , Number of invalids = 4342\n",
            "gen = 101 , Best fitness = (0.23450000000000004,) , Number of invalids = 4375\n",
            "gen = 102 , Best fitness = (0.23450000000000004,) , Number of invalids = 4374\n",
            "gen = 103 , Best fitness = (0.23450000000000004,) , Number of invalids = 4347\n",
            "gen = 104 , Best fitness = (0.23450000000000004,) , Number of invalids = 4404\n",
            "gen = 105 , Best fitness = (0.23450000000000004,) , Number of invalids = 4449\n",
            "gen = 106 , Best fitness = (0.23450000000000004,) , Number of invalids = 4487\n",
            "gen = 107 , Best fitness = (0.23450000000000004,) , Number of invalids = 4408\n",
            "gen = 108 , Best fitness = (0.23450000000000004,) , Number of invalids = 4339\n",
            "gen = 109 , Best fitness = (0.23450000000000004,) , Number of invalids = 4433\n",
            "gen = 110 , Best fitness = (0.23450000000000004,) , Number of invalids = 4440\n",
            "gen = 111 , Best fitness = (0.23450000000000004,) , Number of invalids = 4511\n",
            "gen = 112 , Best fitness = (0.23450000000000004,) , Number of invalids = 4458\n",
            "gen = 113 , Best fitness = (0.23450000000000004,) , Number of invalids = 4467\n",
            "gen = 114 , Best fitness = (0.23450000000000004,) , Number of invalids = 4388\n",
            "gen = 115 , Best fitness = (0.23450000000000004,) , Number of invalids = 4397\n",
            "gen = 116 , Best fitness = (0.23450000000000004,) , Number of invalids = 4430\n",
            "gen = 117 , Best fitness = (0.23450000000000004,) , Number of invalids = 4557\n",
            "gen = 118 , Best fitness = (0.23450000000000004,) , Number of invalids = 4592\n",
            "gen = 119 , Best fitness = (0.23450000000000004,) , Number of invalids = 4648\n",
            "gen = 120 , Best fitness = (0.23450000000000004,) , Number of invalids = 4601\n",
            "gen = 121 , Best fitness = (0.23450000000000004,) , Number of invalids = 4621\n",
            "gen = 122 , Best fitness = (0.23450000000000004,) , Number of invalids = 4637\n",
            "gen = 123 , Best fitness = (0.23450000000000004,) , Number of invalids = 4694\n",
            "gen = 124 , Best fitness = (0.23450000000000004,) , Number of invalids = 4702\n",
            "gen = 125 , Best fitness = (0.23450000000000004,) , Number of invalids = 4793\n",
            "gen = 126 , Best fitness = (0.23450000000000004,) , Number of invalids = 4719\n",
            "gen = 127 , Best fitness = (0.23450000000000004,) , Number of invalids = 4780\n",
            "gen = 128 , Best fitness = (0.23450000000000004,) , Number of invalids = 4671\n",
            "gen = 129 , Best fitness = (0.23450000000000004,) , Number of invalids = 4777\n",
            "gen = 130 , Best fitness = (0.23450000000000004,) , Number of invalids = 4831\n",
            "gen = 131 , Best fitness = (0.23450000000000004,) , Number of invalids = 4827\n",
            "gen = 132 , Best fitness = (0.23450000000000004,) , Number of invalids = 4891\n",
            "gen = 133 , Best fitness = (0.23450000000000004,) , Number of invalids = 4940\n",
            "gen = 134 , Best fitness = (0.23450000000000004,) , Number of invalids = 4882\n",
            "gen = 135 , Best fitness = (0.23450000000000004,) , Number of invalids = 4925\n",
            "gen = 136 , Best fitness = (0.23450000000000004,) , Number of invalids = 4958\n",
            "gen = 137 , Best fitness = (0.23450000000000004,) , Number of invalids = 5033\n",
            "gen = 138 , Best fitness = (0.23450000000000004,) , Number of invalids = 5059\n",
            "gen = 139 , Best fitness = (0.23450000000000004,) , Number of invalids = 5039\n",
            "gen = 140 , Best fitness = (0.23450000000000004,) , Number of invalids = 5126\n",
            "gen = 141 , Best fitness = (0.23450000000000004,) , Number of invalids = 5181\n",
            "gen = 142 , Best fitness = (0.23450000000000004,) , Number of invalids = 5174\n",
            "gen = 143 , Best fitness = (0.23450000000000004,) , Number of invalids = 5157\n",
            "gen = 144 , Best fitness = (0.23450000000000004,) , Number of invalids = 5207\n",
            "gen = 145 , Best fitness = (0.23450000000000004,) , Number of invalids = 5209\n",
            "gen = 146 , Best fitness = (0.23450000000000004,) , Number of invalids = 5280\n",
            "gen = 147 , Best fitness = (0.23450000000000004,) , Number of invalids = 5195\n",
            "gen = 148 , Best fitness = (0.23450000000000004,) , Number of invalids = 5290\n",
            "gen = 149 , Best fitness = (0.23450000000000004,) , Number of invalids = 5366\n",
            "gen = 150 , Best fitness = (0.23450000000000004,) , Number of invalids = 5418\n",
            "gen = 151 , Best fitness = (0.23450000000000004,) , Number of invalids = 5374\n",
            "gen = 152 , Best fitness = (0.23450000000000004,) , Number of invalids = 5408\n",
            "gen = 153 , Best fitness = (0.23450000000000004,) , Number of invalids = 5445\n",
            "gen = 154 , Best fitness = (0.23450000000000004,) , Number of invalids = 5454\n",
            "gen = 155 , Best fitness = (0.23450000000000004,) , Number of invalids = 5445\n",
            "gen = 156 , Best fitness = (0.23450000000000004,) , Number of invalids = 5450\n",
            "gen = 157 , Best fitness = (0.23450000000000004,) , Number of invalids = 5441\n",
            "gen = 158 , Best fitness = (0.23450000000000004,) , Number of invalids = 5333\n",
            "gen = 159 , Best fitness = (0.23450000000000004,) , Number of invalids = 5340\n",
            "gen = 160 , Best fitness = (0.23450000000000004,) , Number of invalids = 5437\n",
            "gen = 161 , Best fitness = (0.23450000000000004,) , Number of invalids = 5353\n",
            "gen = 162 , Best fitness = (0.23450000000000004,) , Number of invalids = 5359\n",
            "gen = 163 , Best fitness = (0.23450000000000004,) , Number of invalids = 5337\n",
            "gen = 164 , Best fitness = (0.23450000000000004,) , Number of invalids = 5329\n",
            "gen = 165 , Best fitness = (0.23450000000000004,) , Number of invalids = 5315\n",
            "gen = 166 , Best fitness = (0.23450000000000004,) , Number of invalids = 5349\n",
            "gen = 167 , Best fitness = (0.23450000000000004,) , Number of invalids = 5366\n",
            "gen = 168 , Best fitness = (0.23450000000000004,) , Number of invalids = 5401\n",
            "gen = 169 , Best fitness = (0.23450000000000004,) , Number of invalids = 5445\n",
            "gen = 170 , Best fitness = (0.23450000000000004,) , Number of invalids = 5500\n",
            "gen = 171 , Best fitness = (0.23450000000000004,) , Number of invalids = 5563\n",
            "gen = 172 , Best fitness = (0.23450000000000004,) , Number of invalids = 5475\n",
            "gen = 173 , Best fitness = (0.23450000000000004,) , Number of invalids = 5592\n",
            "gen = 174 , Best fitness = (0.23450000000000004,) , Number of invalids = 5587\n",
            "gen = 175 , Best fitness = (0.23450000000000004,) , Number of invalids = 5630\n",
            "gen = 176 , Best fitness = (0.23450000000000004,) , Number of invalids = 5522\n",
            "gen = 177 , Best fitness = (0.23450000000000004,) , Number of invalids = 5562\n",
            "gen = 178 , Best fitness = (0.23450000000000004,) , Number of invalids = 5632\n",
            "gen = 179 , Best fitness = (0.23450000000000004,) , Number of invalids = 5569\n",
            "gen = 180 , Best fitness = (0.23450000000000004,) , Number of invalids = 5594\n",
            "gen = 181 , Best fitness = (0.23450000000000004,) , Number of invalids = 5558\n",
            "gen = 182 , Best fitness = (0.23450000000000004,) , Number of invalids = 5583\n",
            "gen = 183 , Best fitness = (0.23450000000000004,) , Number of invalids = 5595\n",
            "gen = 184 , Best fitness = (0.23450000000000004,) , Number of invalids = 5647\n",
            "gen = 185 , Best fitness = (0.23450000000000004,) , Number of invalids = 5691\n",
            "gen = 186 , Best fitness = (0.23450000000000004,) , Number of invalids = 5699\n",
            "gen = 187 , Best fitness = (0.23450000000000004,) , Number of invalids = 5751\n",
            "gen = 188 , Best fitness = (0.23450000000000004,) , Number of invalids = 5732\n",
            "gen = 189 , Best fitness = (0.23450000000000004,) , Number of invalids = 5837\n",
            "gen = 190 , Best fitness = (0.23450000000000004,) , Number of invalids = 5846\n",
            "gen = 191 , Best fitness = (0.23450000000000004,) , Number of invalids = 5926\n",
            "gen = 192 , Best fitness = (0.23450000000000004,) , Number of invalids = 5980\n",
            "gen = 193 , Best fitness = (0.23450000000000004,) , Number of invalids = 6025\n",
            "gen = 194 , Best fitness = (0.23450000000000004,) , Number of invalids = 5968\n",
            "gen = 195 , Best fitness = (0.23450000000000004,) , Number of invalids = 5975\n",
            "gen = 196 , Best fitness = (0.23450000000000004,) , Number of invalids = 5943\n",
            "gen = 197 , Best fitness = (0.23450000000000004,) , Number of invalids = 5938\n",
            "gen = 198 , Best fitness = (0.23450000000000004,) , Number of invalids = 5970\n",
            "gen = 199 , Best fitness = (0.23450000000000004,) , Number of invalids = 5999\n",
            "gen = 200 , Best fitness = (0.23450000000000004,) , Number of invalids = 5971\n",
            "gen = 201 , Best fitness = (0.23450000000000004,) , Number of invalids = 5943\n",
            "gen = 202 , Best fitness = (0.23450000000000004,) , Number of invalids = 6026\n",
            "gen = 203 , Best fitness = (0.23450000000000004,) , Number of invalids = 6017\n",
            "gen = 204 , Best fitness = (0.23450000000000004,) , Number of invalids = 5976\n",
            "gen = 205 , Best fitness = (0.23450000000000004,) , Number of invalids = 5977\n",
            "gen = 206 , Best fitness = (0.23450000000000004,) , Number of invalids = 5889\n",
            "gen = 207 , Best fitness = (0.23450000000000004,) , Number of invalids = 5866\n",
            "gen = 208 , Best fitness = (0.23450000000000004,) , Number of invalids = 5888\n",
            "gen = 209 , Best fitness = (0.23450000000000004,) , Number of invalids = 6030\n",
            "gen = 210 , Best fitness = (0.23450000000000004,) , Number of invalids = 6014\n",
            "gen = 211 , Best fitness = (0.23450000000000004,) , Number of invalids = 5896\n",
            "gen = 212 , Best fitness = (0.23450000000000004,) , Number of invalids = 5910\n",
            "gen = 213 , Best fitness = (0.23450000000000004,) , Number of invalids = 6013\n",
            "gen = 214 , Best fitness = (0.23450000000000004,) , Number of invalids = 5982\n",
            "gen = 215 , Best fitness = (0.23450000000000004,) , Number of invalids = 5895\n",
            "gen = 216 , Best fitness = (0.23450000000000004,) , Number of invalids = 5905\n",
            "gen = 217 , Best fitness = (0.23450000000000004,) , Number of invalids = 5951\n",
            "gen = 218 , Best fitness = (0.23450000000000004,) , Number of invalids = 5946\n",
            "gen = 219 , Best fitness = (0.23450000000000004,) , Number of invalids = 6036\n",
            "gen = 220 , Best fitness = (0.23450000000000004,) , Number of invalids = 5952\n",
            "gen = 221 , Best fitness = (0.23450000000000004,) , Number of invalids = 5986\n",
            "gen = 222 , Best fitness = (0.23450000000000004,) , Number of invalids = 6053\n",
            "gen = 223 , Best fitness = (0.23450000000000004,) , Number of invalids = 6070\n",
            "gen = 224 , Best fitness = (0.23450000000000004,) , Number of invalids = 6082\n",
            "gen = 225 , Best fitness = (0.23450000000000004,) , Number of invalids = 6104\n",
            "gen = 226 , Best fitness = (0.23450000000000004,) , Number of invalids = 6121\n",
            "gen = 227 , Best fitness = (0.23450000000000004,) , Number of invalids = 6086\n",
            "gen = 228 , Best fitness = (0.23450000000000004,) , Number of invalids = 6120\n",
            "gen = 229 , Best fitness = (0.23450000000000004,) , Number of invalids = 6052\n",
            "gen = 230 , Best fitness = (0.23450000000000004,) , Number of invalids = 6062\n",
            "gen = 231 , Best fitness = (0.23450000000000004,) , Number of invalids = 6104\n",
            "gen = 232 , Best fitness = (0.23450000000000004,) , Number of invalids = 6074\n",
            "gen = 233 , Best fitness = (0.23450000000000004,) , Number of invalids = 6069\n",
            "gen = 234 , Best fitness = (0.23450000000000004,) , Number of invalids = 6155\n",
            "gen = 235 , Best fitness = (0.23450000000000004,) , Number of invalids = 6203\n",
            "gen = 236 , Best fitness = (0.23450000000000004,) , Number of invalids = 6207\n",
            "gen = 237 , Best fitness = (0.23450000000000004,) , Number of invalids = 6243\n",
            "gen = 238 , Best fitness = (0.23450000000000004,) , Number of invalids = 6289\n",
            "gen = 239 , Best fitness = (0.23450000000000004,) , Number of invalids = 6319\n",
            "gen = 240 , Best fitness = (0.23450000000000004,) , Number of invalids = 6294\n",
            "gen = 241 , Best fitness = (0.23450000000000004,) , Number of invalids = 6270\n",
            "gen = 242 , Best fitness = (0.23450000000000004,) , Number of invalids = 6272\n",
            "gen = 243 , Best fitness = (0.23450000000000004,) , Number of invalids = 6240\n",
            "gen = 244 , Best fitness = (0.23450000000000004,) , Number of invalids = 6278\n",
            "gen = 245 , Best fitness = (0.23450000000000004,) , Number of invalids = 6291\n",
            "gen = 246 , Best fitness = (0.23450000000000004,) , Number of invalids = 6296\n",
            "gen = 247 , Best fitness = (0.23450000000000004,) , Number of invalids = 6254\n",
            "gen = 248 , Best fitness = (0.23450000000000004,) , Number of invalids = 6187\n",
            "gen = 249 , Best fitness = (0.23450000000000004,) , Number of invalids = 6181\n",
            "gen = 250 , Best fitness = (0.23450000000000004,) , Number of invalids = 6211\n",
            "gen = 251 , Best fitness = (0.23450000000000004,) , Number of invalids = 6287\n",
            "gen = 252 , Best fitness = (0.23450000000000004,) , Number of invalids = 6383\n",
            "gen = 253 , Best fitness = (0.23450000000000004,) , Number of invalids = 6392\n",
            "gen = 254 , Best fitness = (0.23450000000000004,) , Number of invalids = 6395\n",
            "gen = 255 , Best fitness = (0.23450000000000004,) , Number of invalids = 6484\n",
            "gen = 256 , Best fitness = (0.23450000000000004,) , Number of invalids = 6428\n",
            "gen = 257 , Best fitness = (0.23450000000000004,) , Number of invalids = 6381\n",
            "gen = 258 , Best fitness = (0.23450000000000004,) , Number of invalids = 6414\n",
            "gen = 259 , Best fitness = (0.23450000000000004,) , Number of invalids = 6395\n",
            "gen = 260 , Best fitness = (0.23450000000000004,) , Number of invalids = 6459\n",
            "gen = 261 , Best fitness = (0.23450000000000004,) , Number of invalids = 6349\n",
            "gen = 262 , Best fitness = (0.23450000000000004,) , Number of invalids = 6364\n",
            "gen = 263 , Best fitness = (0.23450000000000004,) , Number of invalids = 6389\n",
            "gen = 264 , Best fitness = (0.23450000000000004,) , Number of invalids = 6386\n",
            "gen = 265 , Best fitness = (0.23450000000000004,) , Number of invalids = 6402\n",
            "gen = 266 , Best fitness = (0.23450000000000004,) , Number of invalids = 6445\n",
            "gen = 267 , Best fitness = (0.23450000000000004,) , Number of invalids = 6448\n",
            "gen = 268 , Best fitness = (0.23450000000000004,) , Number of invalids = 6519\n",
            "gen = 269 , Best fitness = (0.23450000000000004,) , Number of invalids = 6513\n",
            "gen = 270 , Best fitness = (0.23450000000000004,) , Number of invalids = 6534\n",
            "gen = 271 , Best fitness = (0.23450000000000004,) , Number of invalids = 6560\n",
            "gen = 272 , Best fitness = (0.23450000000000004,) , Number of invalids = 6520\n",
            "gen = 273 , Best fitness = (0.23450000000000004,) , Number of invalids = 6476\n",
            "gen = 274 , Best fitness = (0.23450000000000004,) , Number of invalids = 6522\n",
            "gen = 275 , Best fitness = (0.23450000000000004,) , Number of invalids = 6597\n",
            "gen = 276 , Best fitness = (0.23450000000000004,) , Number of invalids = 6575\n",
            "gen = 277 , Best fitness = (0.23450000000000004,) , Number of invalids = 6593\n",
            "gen = 278 , Best fitness = (0.23450000000000004,) , Number of invalids = 6729\n",
            "gen = 279 , Best fitness = (0.23450000000000004,) , Number of invalids = 6694\n",
            "gen = 280 , Best fitness = (0.23450000000000004,) , Number of invalids = 6690\n",
            "gen = 281 , Best fitness = (0.23450000000000004,) , Number of invalids = 6775\n",
            "gen = 282 , Best fitness = (0.23450000000000004,) , Number of invalids = 6709\n",
            "gen = 283 , Best fitness = (0.23450000000000004,) , Number of invalids = 6716\n",
            "gen = 284 , Best fitness = (0.23450000000000004,) , Number of invalids = 6677\n",
            "gen = 285 , Best fitness = (0.23450000000000004,) , Number of invalids = 6653\n",
            "gen = 286 , Best fitness = (0.23450000000000004,) , Number of invalids = 6628\n",
            "gen = 287 , Best fitness = (0.23450000000000004,) , Number of invalids = 6648\n",
            "gen = 288 , Best fitness = (0.23450000000000004,) , Number of invalids = 6681\n",
            "gen = 289 , Best fitness = (0.23450000000000004,) , Number of invalids = 6708\n",
            "gen = 290 , Best fitness = (0.23450000000000004,) , Number of invalids = 6647\n",
            "gen = 291 , Best fitness = (0.23450000000000004,) , Number of invalids = 6681\n",
            "gen = 292 , Best fitness = (0.23450000000000004,) , Number of invalids = 6700\n",
            "gen = 293 , Best fitness = (0.23450000000000004,) , Number of invalids = 6745\n",
            "gen = 294 , Best fitness = (0.23450000000000004,) , Number of invalids = 6701\n",
            "gen = 295 , Best fitness = (0.23450000000000004,) , Number of invalids = 6729\n",
            "gen = 296 , Best fitness = (0.23450000000000004,) , Number of invalids = 6776\n",
            "gen = 297 , Best fitness = (0.23450000000000004,) , Number of invalids = 6832\n",
            "gen = 298 , Best fitness = (0.23450000000000004,) , Number of invalids = 6827\n",
            "gen = 299 , Best fitness = (0.23450000000000004,) , Number of invalids = 6807\n",
            "gen = 300 , Best fitness = (0.23450000000000004,) , Number of invalids = 6791\n",
            "gen = 301 , Best fitness = (0.23450000000000004,) , Number of invalids = 6830\n",
            "gen = 302 , Best fitness = (0.23450000000000004,) , Number of invalids = 6887\n",
            "gen = 303 , Best fitness = (0.23450000000000004,) , Number of invalids = 6904\n",
            "gen = 304 , Best fitness = (0.23450000000000004,) , Number of invalids = 6906\n",
            "gen = 305 , Best fitness = (0.23450000000000004,) , Number of invalids = 6916\n",
            "gen = 306 , Best fitness = (0.23450000000000004,) , Number of invalids = 6909\n",
            "gen = 307 , Best fitness = (0.23450000000000004,) , Number of invalids = 6969\n",
            "gen = 308 , Best fitness = (0.23450000000000004,) , Number of invalids = 7004\n",
            "gen = 309 , Best fitness = (0.23450000000000004,) , Number of invalids = 6945\n",
            "gen = 310 , Best fitness = (0.23450000000000004,) , Number of invalids = 6893\n",
            "gen = 311 , Best fitness = (0.23450000000000004,) , Number of invalids = 6913\n",
            "gen = 312 , Best fitness = (0.23450000000000004,) , Number of invalids = 6810\n",
            "gen = 313 , Best fitness = (0.23450000000000004,) , Number of invalids = 6861\n",
            "gen = 314 , Best fitness = (0.23450000000000004,) , Number of invalids = 6774\n",
            "gen = 315 , Best fitness = (0.23450000000000004,) , Number of invalids = 6712\n",
            "gen = 316 , Best fitness = (0.23450000000000004,) , Number of invalids = 6773\n",
            "gen = 317 , Best fitness = (0.23450000000000004,) , Number of invalids = 6837\n",
            "gen = 318 , Best fitness = (0.23450000000000004,) , Number of invalids = 6798\n",
            "gen = 319 , Best fitness = (0.23450000000000004,) , Number of invalids = 6820\n",
            "gen = 320 , Best fitness = (0.23450000000000004,) , Number of invalids = 6843\n",
            "gen = 321 , Best fitness = (0.23450000000000004,) , Number of invalids = 6782\n",
            "gen = 322 , Best fitness = (0.23450000000000004,) , Number of invalids = 6790\n",
            "gen = 323 , Best fitness = (0.23450000000000004,) , Number of invalids = 6797\n",
            "gen = 324 , Best fitness = (0.23450000000000004,) , Number of invalids = 6784\n",
            "gen = 325 , Best fitness = (0.23450000000000004,) , Number of invalids = 6772\n",
            "gen = 326 , Best fitness = (0.23450000000000004,) , Number of invalids = 6776\n",
            "gen = 327 , Best fitness = (0.23450000000000004,) , Number of invalids = 6898\n",
            "gen = 328 , Best fitness = (0.23450000000000004,) , Number of invalids = 6875\n",
            "gen = 329 , Best fitness = (0.23450000000000004,) , Number of invalids = 6861\n",
            "gen = 330 , Best fitness = (0.23450000000000004,) , Number of invalids = 6842\n",
            "gen = 331 , Best fitness = (0.23450000000000004,) , Number of invalids = 6896\n",
            "gen = 332 , Best fitness = (0.23450000000000004,) , Number of invalids = 6876\n",
            "gen = 333 , Best fitness = (0.23450000000000004,) , Number of invalids = 6891\n",
            "gen = 334 , Best fitness = (0.23450000000000004,) , Number of invalids = 6911\n",
            "gen = 335 , Best fitness = (0.23450000000000004,) , Number of invalids = 6892\n",
            "gen = 336 , Best fitness = (0.23450000000000004,) , Number of invalids = 6951\n",
            "gen = 337 , Best fitness = (0.23450000000000004,) , Number of invalids = 7024\n",
            "gen = 338 , Best fitness = (0.23450000000000004,) , Number of invalids = 7054\n",
            "gen = 339 , Best fitness = (0.23450000000000004,) , Number of invalids = 7095\n",
            "gen = 340 , Best fitness = (0.23450000000000004,) , Number of invalids = 7070\n",
            "gen = 341 , Best fitness = (0.23450000000000004,) , Number of invalids = 7079\n",
            "gen = 342 , Best fitness = (0.23450000000000004,) , Number of invalids = 7069\n",
            "gen = 343 , Best fitness = (0.23450000000000004,) , Number of invalids = 7044\n",
            "gen = 344 , Best fitness = (0.23450000000000004,) , Number of invalids = 7088\n",
            "gen = 345 , Best fitness = (0.23450000000000004,) , Number of invalids = 7157\n",
            "gen = 346 , Best fitness = (0.23450000000000004,) , Number of invalids = 7055\n",
            "gen = 347 , Best fitness = (0.23450000000000004,) , Number of invalids = 7140\n",
            "gen = 348 , Best fitness = (0.23450000000000004,) , Number of invalids = 7045\n",
            "gen = 349 , Best fitness = (0.23450000000000004,) , Number of invalids = 7073\n",
            "gen = 350 , Best fitness = (0.23450000000000004,) , Number of invalids = 7077\n",
            "gen = 351 , Best fitness = (0.23450000000000004,) , Number of invalids = 7130\n",
            "gen = 352 , Best fitness = (0.23450000000000004,) , Number of invalids = 7121\n",
            "gen = 353 , Best fitness = (0.23450000000000004,) , Number of invalids = 7185\n",
            "gen = 354 , Best fitness = (0.23450000000000004,) , Number of invalids = 7118\n",
            "gen = 355 , Best fitness = (0.23450000000000004,) , Number of invalids = 7161\n",
            "gen = 356 , Best fitness = (0.23450000000000004,) , Number of invalids = 7212\n",
            "gen = 357 , Best fitness = (0.23450000000000004,) , Number of invalids = 7225\n",
            "gen = 358 , Best fitness = (0.23450000000000004,) , Number of invalids = 7204\n",
            "gen = 359 , Best fitness = (0.23450000000000004,) , Number of invalids = 7205\n",
            "gen = 360 , Best fitness = (0.23450000000000004,) , Number of invalids = 7179\n",
            "gen = 361 , Best fitness = (0.23450000000000004,) , Number of invalids = 7197\n",
            "gen = 362 , Best fitness = (0.23450000000000004,) , Number of invalids = 7183\n",
            "gen = 363 , Best fitness = (0.23450000000000004,) , Number of invalids = 7104\n",
            "gen = 364 , Best fitness = (0.23450000000000004,) , Number of invalids = 7129\n",
            "gen = 365 , Best fitness = (0.23450000000000004,) , Number of invalids = 7103\n",
            "gen = 366 , Best fitness = (0.23450000000000004,) , Number of invalids = 7116\n",
            "gen = 367 , Best fitness = (0.23450000000000004,) , Number of invalids = 7138\n",
            "gen = 368 , Best fitness = (0.23450000000000004,) , Number of invalids = 7084\n",
            "gen = 369 , Best fitness = (0.23450000000000004,) , Number of invalids = 7079\n",
            "gen = 370 , Best fitness = (0.23450000000000004,) , Number of invalids = 6947\n",
            "gen = 371 , Best fitness = (0.23450000000000004,) , Number of invalids = 6955\n",
            "gen = 372 , Best fitness = (0.23450000000000004,) , Number of invalids = 7040\n",
            "gen = 373 , Best fitness = (0.23450000000000004,) , Number of invalids = 6987\n",
            "gen = 374 , Best fitness = (0.23450000000000004,) , Number of invalids = 6935\n",
            "gen = 375 , Best fitness = (0.23450000000000004,) , Number of invalids = 6941\n",
            "gen = 376 , Best fitness = (0.23450000000000004,) , Number of invalids = 6914\n",
            "gen = 377 , Best fitness = (0.23450000000000004,) , Number of invalids = 6961\n",
            "gen = 378 , Best fitness = (0.23450000000000004,) , Number of invalids = 7053\n",
            "gen = 379 , Best fitness = (0.23450000000000004,) , Number of invalids = 7145\n",
            "gen = 380 , Best fitness = (0.23450000000000004,) , Number of invalids = 7163\n",
            "gen = 381 , Best fitness = (0.23450000000000004,) , Number of invalids = 7175\n",
            "gen = 382 , Best fitness = (0.23450000000000004,) , Number of invalids = 7224\n",
            "gen = 383 , Best fitness = (0.23450000000000004,) , Number of invalids = 7215\n",
            "gen = 384 , Best fitness = (0.23450000000000004,) , Number of invalids = 7131\n",
            "gen = 385 , Best fitness = (0.23450000000000004,) , Number of invalids = 7106\n",
            "gen = 386 , Best fitness = (0.23450000000000004,) , Number of invalids = 7152\n",
            "gen = 387 , Best fitness = (0.23450000000000004,) , Number of invalids = 7171\n",
            "gen = 388 , Best fitness = (0.23450000000000004,) , Number of invalids = 7181\n",
            "gen = 389 , Best fitness = (0.23450000000000004,) , Number of invalids = 7137\n",
            "gen = 390 , Best fitness = (0.23450000000000004,) , Number of invalids = 7199\n",
            "gen = 391 , Best fitness = (0.23450000000000004,) , Number of invalids = 7194\n",
            "gen = 392 , Best fitness = (0.23450000000000004,) , Number of invalids = 7197\n",
            "gen = 393 , Best fitness = (0.23450000000000004,) , Number of invalids = 7201\n",
            "gen = 394 , Best fitness = (0.23450000000000004,) , Number of invalids = 7139\n",
            "gen = 395 , Best fitness = (0.23450000000000004,) , Number of invalids = 7118\n",
            "gen = 396 , Best fitness = (0.23450000000000004,) , Number of invalids = 7099\n",
            "gen = 397 , Best fitness = (0.23450000000000004,) , Number of invalids = 7118\n",
            "gen = 398 , Best fitness = (0.23450000000000004,) , Number of invalids = 7056\n",
            "gen = 399 , Best fitness = (0.23450000000000004,) , Number of invalids = 7017\n",
            "gen = 400 , Best fitness = (0.23450000000000004,) , Number of invalids = 6946\n",
            "gen = 401 , Best fitness = (0.23450000000000004,) , Number of invalids = 7037\n",
            "gen = 402 , Best fitness = (0.23450000000000004,) , Number of invalids = 6995\n",
            "gen = 403 , Best fitness = (0.23450000000000004,) , Number of invalids = 6948\n",
            "gen = 404 , Best fitness = (0.23450000000000004,) , Number of invalids = 6995\n",
            "gen = 405 , Best fitness = (0.23450000000000004,) , Number of invalids = 7053\n",
            "gen = 406 , Best fitness = (0.23450000000000004,) , Number of invalids = 7042\n",
            "gen = 407 , Best fitness = (0.23450000000000004,) , Number of invalids = 7098\n",
            "gen = 408 , Best fitness = (0.23450000000000004,) , Number of invalids = 7144\n",
            "gen = 409 , Best fitness = (0.23450000000000004,) , Number of invalids = 7162\n",
            "gen = 410 , Best fitness = (0.23450000000000004,) , Number of invalids = 7064\n",
            "gen = 411 , Best fitness = (0.23450000000000004,) , Number of invalids = 7143\n",
            "gen = 412 , Best fitness = (0.23450000000000004,) , Number of invalids = 7075\n",
            "gen = 413 , Best fitness = (0.23450000000000004,) , Number of invalids = 7135\n",
            "gen = 414 , Best fitness = (0.23450000000000004,) , Number of invalids = 7140\n",
            "gen = 415 , Best fitness = (0.23450000000000004,) , Number of invalids = 7156\n",
            "gen = 416 , Best fitness = (0.23450000000000004,) , Number of invalids = 7135\n",
            "gen = 417 , Best fitness = (0.23450000000000004,) , Number of invalids = 7077\n",
            "gen = 418 , Best fitness = (0.23450000000000004,) , Number of invalids = 7073\n",
            "gen = 419 , Best fitness = (0.23450000000000004,) , Number of invalids = 7104\n",
            "gen = 420 , Best fitness = (0.23450000000000004,) , Number of invalids = 7229\n",
            "gen = 421 , Best fitness = (0.23450000000000004,) , Number of invalids = 7238\n",
            "gen = 422 , Best fitness = (0.23450000000000004,) , Number of invalids = 7205\n",
            "gen = 423 , Best fitness = (0.23450000000000004,) , Number of invalids = 7106\n",
            "gen = 424 , Best fitness = (0.23450000000000004,) , Number of invalids = 7122\n",
            "gen = 425 , Best fitness = (0.23450000000000004,) , Number of invalids = 7166\n",
            "gen = 426 , Best fitness = (0.23450000000000004,) , Number of invalids = 7167\n",
            "gen = 427 , Best fitness = (0.22050000000000003,) , Number of invalids = 7173\n",
            "gen = 428 , Best fitness = (0.22050000000000003,) , Number of invalids = 7072\n",
            "gen = 429 , Best fitness = (0.22050000000000003,) , Number of invalids = 7120\n",
            "gen = 430 , Best fitness = (0.22050000000000003,) , Number of invalids = 7009\n",
            "gen = 431 , Best fitness = (0.22050000000000003,) , Number of invalids = 7007\n",
            "gen = 432 , Best fitness = (0.22050000000000003,) , Number of invalids = 7041\n",
            "gen = 433 , Best fitness = (0.22050000000000003,) , Number of invalids = 7054\n",
            "gen = 434 , Best fitness = (0.22050000000000003,) , Number of invalids = 7075\n",
            "gen = 435 , Best fitness = (0.22050000000000003,) , Number of invalids = 7037\n",
            "gen = 436 , Best fitness = (0.22050000000000003,) , Number of invalids = 7059\n",
            "gen = 437 , Best fitness = (0.22050000000000003,) , Number of invalids = 7053\n",
            "gen = 438 , Best fitness = (0.22050000000000003,) , Number of invalids = 7113\n",
            "gen = 439 , Best fitness = (0.22050000000000003,) , Number of invalids = 7089\n",
            "gen = 440 , Best fitness = (0.22050000000000003,) , Number of invalids = 7121\n",
            "gen = 441 , Best fitness = (0.22050000000000003,) , Number of invalids = 7169\n",
            "gen = 442 , Best fitness = (0.22050000000000003,) , Number of invalids = 7111\n",
            "gen = 443 , Best fitness = (0.22050000000000003,) , Number of invalids = 7099\n",
            "gen = 444 , Best fitness = (0.22050000000000003,) , Number of invalids = 7137\n",
            "gen = 445 , Best fitness = (0.22050000000000003,) , Number of invalids = 7160\n",
            "gen = 446 , Best fitness = (0.22050000000000003,) , Number of invalids = 7205\n",
            "gen = 447 , Best fitness = (0.22050000000000003,) , Number of invalids = 7190\n",
            "gen = 448 , Best fitness = (0.22050000000000003,) , Number of invalids = 7251\n",
            "gen = 449 , Best fitness = (0.22050000000000003,) , Number of invalids = 7188\n",
            "gen = 450 , Best fitness = (0.22050000000000003,) , Number of invalids = 7288\n",
            "gen = 451 , Best fitness = (0.22050000000000003,) , Number of invalids = 7231\n",
            "gen = 452 , Best fitness = (0.22050000000000003,) , Number of invalids = 7177\n",
            "gen = 453 , Best fitness = (0.22050000000000003,) , Number of invalids = 7319\n",
            "gen = 454 , Best fitness = (0.22050000000000003,) , Number of invalids = 7257\n",
            "gen = 455 , Best fitness = (0.22050000000000003,) , Number of invalids = 7272\n",
            "gen = 456 , Best fitness = (0.22050000000000003,) , Number of invalids = 7171\n",
            "gen = 457 , Best fitness = (0.22050000000000003,) , Number of invalids = 7168\n",
            "gen = 458 , Best fitness = (0.22050000000000003,) , Number of invalids = 7185\n",
            "gen = 459 , Best fitness = (0.22050000000000003,) , Number of invalids = 7182\n",
            "gen = 460 , Best fitness = (0.22050000000000003,) , Number of invalids = 7121\n",
            "gen = 461 , Best fitness = (0.22050000000000003,) , Number of invalids = 7144\n",
            "gen = 462 , Best fitness = (0.22050000000000003,) , Number of invalids = 7147\n",
            "gen = 463 , Best fitness = (0.22050000000000003,) , Number of invalids = 7127\n",
            "gen = 464 , Best fitness = (0.22050000000000003,) , Number of invalids = 7169\n",
            "gen = 465 , Best fitness = (0.22050000000000003,) , Number of invalids = 7182\n",
            "gen = 466 , Best fitness = (0.22050000000000003,) , Number of invalids = 7281\n",
            "gen = 467 , Best fitness = (0.22050000000000003,) , Number of invalids = 7266\n",
            "gen = 468 , Best fitness = (0.22050000000000003,) , Number of invalids = 7233\n",
            "gen = 469 , Best fitness = (0.22050000000000003,) , Number of invalids = 7209\n",
            "gen = 470 , Best fitness = (0.22050000000000003,) , Number of invalids = 7185\n",
            "gen = 471 , Best fitness = (0.22050000000000003,) , Number of invalids = 7252\n",
            "gen = 472 , Best fitness = (0.22050000000000003,) , Number of invalids = 7179\n",
            "gen = 473 , Best fitness = (0.22050000000000003,) , Number of invalids = 7235\n",
            "gen = 474 , Best fitness = (0.22050000000000003,) , Number of invalids = 7234\n",
            "gen = 475 , Best fitness = (0.22050000000000003,) , Number of invalids = 7251\n",
            "gen = 476 , Best fitness = (0.22050000000000003,) , Number of invalids = 7272\n",
            "gen = 477 , Best fitness = (0.22050000000000003,) , Number of invalids = 7219\n",
            "gen = 478 , Best fitness = (0.22050000000000003,) , Number of invalids = 7242\n",
            "gen = 479 , Best fitness = (0.22050000000000003,) , Number of invalids = 7287\n",
            "gen = 480 , Best fitness = (0.22050000000000003,) , Number of invalids = 7331\n",
            "gen = 481 , Best fitness = (0.22050000000000003,) , Number of invalids = 7339\n",
            "gen = 482 , Best fitness = (0.22050000000000003,) , Number of invalids = 7334\n",
            "gen = 483 , Best fitness = (0.22050000000000003,) , Number of invalids = 7263\n",
            "gen = 484 , Best fitness = (0.22050000000000003,) , Number of invalids = 7334\n",
            "gen = 485 , Best fitness = (0.22050000000000003,) , Number of invalids = 7232\n",
            "gen = 486 , Best fitness = (0.22050000000000003,) , Number of invalids = 7222\n",
            "gen = 487 , Best fitness = (0.22050000000000003,) , Number of invalids = 7185\n",
            "gen = 488 , Best fitness = (0.22050000000000003,) , Number of invalids = 7188\n",
            "gen = 489 , Best fitness = (0.22050000000000003,) , Number of invalids = 7172\n",
            "gen = 490 , Best fitness = (0.22050000000000003,) , Number of invalids = 7140\n",
            "gen = 491 , Best fitness = (0.22050000000000003,) , Number of invalids = 7102\n",
            "gen = 492 , Best fitness = (0.22050000000000003,) , Number of invalids = 7080\n",
            "gen = 493 , Best fitness = (0.22050000000000003,) , Number of invalids = 7065\n",
            "gen = 494 , Best fitness = (0.22050000000000003,) , Number of invalids = 7101\n",
            "gen = 495 , Best fitness = (0.22050000000000003,) , Number of invalids = 7166\n",
            "gen = 496 , Best fitness = (0.22050000000000003,) , Number of invalids = 7180\n",
            "gen = 497 , Best fitness = (0.22050000000000003,) , Number of invalids = 7181\n",
            "gen = 498 , Best fitness = (0.22050000000000003,) , Number of invalids = 7097\n",
            "gen = 499 , Best fitness = (0.22050000000000003,) , Number of invalids = 7171\n",
            "gen = 500 , Best fitness = (0.22050000000000003,) , Number of invalids = 7128\n"
          ]
        }
      ],
      "source": [
        "population, logbook = algorithms.ge_eaSimpleWithElitism(population, toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION,\n",
        "                                              ngen=MAX_GENERATIONS, elite_size=ELITE_SIZE,\n",
        "                                              bnf_grammar=BNF_GRAMMAR, \n",
        "                                              codon_size=CODON_SIZE, \n",
        "                                              max_tree_depth=MAX_TREE_DEPTH,\n",
        "                                              max_genome_length=MAX_GENOME_LENGTH,\n",
        "                                              points_train=[X_train2, y_train], \n",
        "                                              codon_consumption=CODON_CONSUMPTION,\n",
        "                                              report_items=REPORT_ITEMS,\n",
        "                                              genome_representation=GENOME_REPRESENTATION,                                              \n",
        "                                              stats=stats, halloffame=hof, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLXak5uTuVuh"
      },
      "source": [
        "Show the best individual as an expression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00RD1VvMtr5J",
        "outputId": "8d88c7c4-00f0-4430-be23-99437a9c0a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best individual: \n",
            " less_than_or_equal(x[1] * x[1],sub(x[2] - x[4],x[5] + mean_(x[6])))\n",
            "\n",
            "Training Fitness:  0.22050000000000003\n",
            "Depth:  7\n",
            "Length of the genome:  18\n",
            "Used portion of the genome: 0.89\n"
          ]
        }
      ],
      "source": [
        "# Best individual\n",
        "import textwrap\n",
        "best = hof.items[0].phenotype\n",
        "print(\"Best individual: \\n\",\"\\n\".join(textwrap.wrap(best,80)))\n",
        "print(\"\\nTraining Fitness: \", hof.items[0].fitness.values[0])\n",
        "print(\"Depth: \", hof.items[0].depth)\n",
        "print(\"Length of the genome: \", len(hof.items[0].genome))\n",
        "print(f'Used portion of the genome: {hof.items[0].used_codons/len(hof.items[0].genome):.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnwyfFGmunWR"
      },
      "source": [
        "Define a function to predict values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "BJgW2-ZFt2-Z"
      },
      "outputs": [],
      "source": [
        "def predict(individual, X):\n",
        "    x = X\n",
        "    \n",
        "    if individual.invalid == True:\n",
        "        return np.NaN,\n",
        "\n",
        "    # Evaluate the expression\n",
        "    try:\n",
        "        pred = eval(individual.phenotype)\n",
        "    except (FloatingPointError, ZeroDivisionError, OverflowError,\n",
        "            MemoryError):\n",
        "        return np.NaN,\n",
        "    assert np.isrealobj(pred)\n",
        "    \n",
        "    _, c = x.shape\n",
        "    \n",
        "    try:\n",
        "        Y_class = [True if pred[i] > 0 else False for i in range(c)]\n",
        "    except (IndexError, TypeError):\n",
        "        return np.NaN,\n",
        "   \n",
        "    return Y_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U87HYdwKud_x"
      },
      "source": [
        "Predict the classes of the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um-DsUo4uefK",
        "outputId": "e3d7e309-c9cc-4809-e8d3-c2f18dfe02fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes of the test set:  [False, True, False, True, False, True, True, True, True, True, True, True, True, False, True, False, False, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, False, True, False, True, True, False, True, False, False, True, True, True, True, False, False, True, True, True, False, True, False, False, True, True, True, True, False, False, True, False, False, False, True, False, False, False, True, True, False, False, True, True, True, True, False, False, False, False, False, False, True, True, True, True, True, True, False, True, True, False, True, True, False, False, True, False, False, False, True, True, True, False, True, False, True, False, False, True, False, False, False, True, False, True, True, True, True, True, True, True, False, False, True, True, False, True, False, True, True, False, False, True, True, True, True, True, True, False, True, False, True, True, True, False, True, False, True, False, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, False, True, False, False, False, True, True, False, True, True, True, True, False, True, False, False, True, False, True, True, True, False, True, False, True, True, True, True, True, False, True, False, True, False, True, False, False, True, False, True, True, True, True, False, False, True, False, True, False, False, True, True, True, True, True, True, True, True, True, True, False, True, False, False, True, False, True, True, True, False, True, False, True, True, True, True, True, False, True, True, False, True, False, True, True, False, True, True, True, False, True, False, True, False, True, True, True, True, False, False, True, True, True, True, True, True, True, True, False, True, False, False, True, True, True, False, False, False, True, True, True, False, False, False, True, False, True, True, True, False, True, True, True, True, True, False, True, False, False, True, False, False, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, False, False, True, True, False, False, True, False, False, True, True, True, False, True, True, False, False, True, True, True, False, False, False, True, False, False, False, True, True, True, True, False, False, True, True, False, False, False, False, True, True, True, True, False, False, False, False, True, False, False, False, False, True, True, False, True, False, True, True, True, True, False, True, False, True, False, True, True, False, True, False, False, False, False, True, True, True, True, False, False, False, True, True, False, True, True, False, False, True, True, False, True, False, False, True, True, False, True, True, True, False, True, True, False, True, True, False, False, True, True, True, True, True, True, True, False, True, False, True, True, False, False, False, False, True, False, False, True, True, True, True, True, True, False, True, False, True, False, True, False, True, True, True, True, True, True, True, False, True, True, True, True, False, False, True, False, False, True, True, False, True, True, True, False, True, True, True, True, True, True, False, True, False, True, False, True, True, False, False, True, False, False, False, True, True, False, True, True, True, False, False, True, False, False, True, False, True, True, True, False, True, True, False, True, True, True, False, True, True, True, True, False, True, True, True, True, False, True, False, False, True, True, False, True, True, False, True, True, True, False, False, False, True, False, True, False, True, True, True, True, True, False, False, True, True, True, True, False, True, True, False, True, True, True, True, False, True, False, False, False, False, True, True, True, False, True, True, False, True, False, True, False, True, False, True, True, True, True, True, False, True, True, True, False, False, True, False, True, False, True, True, False, False, True, True, True, True, False, False, True, True, False, False, True, True, False, True, True, False, True, True, True, True, True, True, False, True, False, False, True, True, True, False, True, True, False, True, True, True, False, True, False, False, False, False, True, True, False, True, True, False, False, True, False, True, False, True, True, True, True, True, True, False, False, True, False, True, False, False, True, True, False, False, False, False, False, True, False, True, False, True, True, True, True, True, False, True, True, True, True, False, True, True, True, True, False, False, False, False, True, False, True, True, True, False, False, False, False, False, True, True, True, True, False, False, True, True, False, True, True, False, True, True, True, True, True, True, False, False, True, False, True, False, False, True, False, True, True, True, False, True, True, True, True, True, False, True, True, True, True, False, True, True, True, True, False, False, True, True, False, True, True, True, False, False, False, True, True, False, True, True, True, False, False, True, True, False, False, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, True, False, False, False, True, True, True, True, True, False, True, True, True, True, False, False, False, True, False, False, True, True, True, False, True, False, True, True, True, True, False, False, True, True, True, True, False, True, False, True, True, False, False, True, True, True, False, False, False, True, True, True, True, True, False, True, True, True, False, True, False, True, False, True, True, False, True, True, True, True, False, True, False, True, True, True, False, True, False, True, True, True, True, False, True, True, True, True, False, True, False, True, True, False, False, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, False, False, False, True, True, False, True, True, True, True, True, True, False, True, False, True, False, True, True, False, True, True, True, False, True, True, False, True, True, True, True, True, False, False, True, True, True, False, True, False, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, False, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, True, True, True, True, False, True, False, False, True, False, False, False, False, True, True, False, False, True, False, False, False, True, False, False, False, True, True, False, True, True, False, False, True, False, False, False, True, True, False, False, False, False, True, True, True, False, True, False, True, False, True, False, False, True, True, False, True, True, False, False, False, False, True, False, True, True, True, False, True, True, False, True, True, True, False, True, False, True, False, True, True, True, False, True, True, True, True, True, True, False, False, True, True, True, False, True, False, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, False, False, False, False, False, False, True, True, True, False, True, True, False, False, True, False, True, True, True, True, False, True, False, False, True, False, True, True, False, True, True, False, False, True, True, False, True, True, False, True, True, False, True, False, True, True, True, True, False, False, True, True, False, False, True, False, True, True, True, False, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, False, False, True, True, False, True, True, False, True, True, True, False, True, True, True, True, True, True, False, True, True, True, False, True, False, True, True, False, False, True, False, True, True, True, True, False, False, True, False, False, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, True, True, False, True, True, False, False, False, False, False, False, False, True, True, True, True, True, False, True, True, True, True, True, False, False, False, True, True, True, True, True, True, False, False, False, True, True, False, False, True, True, True, True, False, False, True, False, True, True, True, True, True, True, True, True, False, False, True, True, True, True, False, True, True, False, True, True, True, False, True, False, False, True, True, True, False, True, False, True, True, True, False, True, False, True, True, True, False, True, False, True, True, False, True, False, True, True, False, True, False, True, True, False, True, False, False, True, True, True, False, True, False, True, True, True, True, True, False, True, True, True, True, False, True, True, False, False, True, True, False, True, False, False, True, True, False, True, True, False, True, True, True, False, True, True, False, True, True, True, False, False, True, True, False, False, False, False, True, True, False, False, False, False, False, False, True, True, False, True, False, True, False, True, True, True, False, True, True, True, False, False, False, False, True, False, False, False, True, True, False, False, True, True, False, True, True, False, True, False, False, True, True, True, False, False, True, False, True, False, False, True, True, True, False, True, True, True, False, True, True, True, True, True, False, False, True, True, True, True, False, False, True, False, True, False, False, True, True, True, False, True, True, True, False, False, True, True, True, True, True, False, False, True, False, True, True, True, True, True, False, False, False, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, False, True, True, False, True, True, True, False, True, False, True, True, True, True, True, False, True, True, False, True, True, False, False, True, True, True, False, False, True, True, True, True, True, True, False, False, True, False, False, False, False, True, True, True, True, False, True, False, False, False, True, True, False, False, False, True, False, True, True, False, True, False, True, False, False, False, True, True, False, False, True, False, True, True, False, True, False, False, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, False, True, True, False, True, False, True, True, True, True, False, False, False, True, True, True, True, False, False, True, False, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, True, False, False, True, True, True, False, False, True, True, False, True, True, True, False, True, False, False, False, True, True, True, True, True, False, False, True, False, True, True, False, False, False, False, False, True, True, False, False, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, False, True, False, False, True, True, False, False, True, False, True, False, True, False, True, True, True, True, True, True, False, True, False, True, True, False, False, True, True, True, True, False, True, True, False, True, True, True, False, True, True, True, True, True, True, False, False, False, False, True, False, False, False, False, True, True, True, True, True, True, False, False, False, False, True, False, False, False, False, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, False, True, True, True, False, True, True, False, True, False, True, True, False, True, True, False, True, True, False, True, True, True, True, True, False, True, True, False, True, True, False, True, False, False, True, False, True, True, True, False, True, True, True, False, True, False, False, False, True, True, True, True, True, True, False, True, True, True, True, False, False, False, True, True, True, False, True, True, False, True, True, False, True, False, True, False, True, False, False, False, False, True, True, False, True, True, False, True, True, True, True, False, False, False, False, True, False, False, False, False, True, True, True, False, True, True, False, True, False, False, True, True, False, True, True, False, True, True, False, True, True, True, False, True, False, True, True, True, True, False, False, False, True, False, False, True, True, True, True, True, True, False, True, True, True, False, False, True, False, True, False, True, True, True, False, False, False, True, False, True, True, True, True, True, False, True, True, True, False, True, False, False, False, True, True, False, False, True, True, True, False, True, True, True, True, False, True, False, True, True, True, True, True, False, True, False, False, False, True, True, False, True, False, False, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, False, True, True, True, True, True, True, False, False, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, False, True, True, False, True, True, False, True, False, True, True, True, True, False, True, True, True, False, True, True, True, False, True, True, True, True, True, False, True, True, True, True, False, True, False, True, False, True, True, False, False, True, True, True, False, True, True, True, True, False, False, False, False, True, True, False, True, True, True, True, True, False, False, True, True, True, False, False, True, False, True, True, True, False, False, True, True, False, True, False, False, True, True, False, True, False, False, True, False, False, True, True, True, True, True, True, True, True, True, False, True, True, False, True, True, True, False, False, True, False, False, True, False, True, False, False, True, True, False, True, False, True, True, False, True, True, False, False, True, False, False, True, False, False, True, True, True, False, True, True, True, True, False, True, False, True, True, True, True, True, False, True, False, True, False, True, True, True, False, True, True, False, True, True, False, True, True, True, False, False, True, False, True, False, True, True, True, True, True, False, True, False, False, True, True, False, False, True, True, False, False, True, True, True, True, True, False, False, True, True, False, True, False, True, False, False, True, True, True, True, True, False, True, False, False, False, True, True, False, False, True, True, True, True, True, True, True, True, False, True, True, True, False, False, True, True, True, True, True, False, False, True, True, False, True, True, False, True, True, False, True, True, True, True, True, True, True, True, False, True, False, True, False, True, False, True, False, True, True, False, True, True, True, False, False, True, True, True, True, False, True, True, True, True, False, False, True, True, False, True, True, True, False, True, True, False, True, True, True, False, False, True, True, True, True, True, False, True, True, True, True, False, True, False, False, True, False, False, True, False, False, False, True, False, True, True, False, True, True, True, True, True, False, True, False, True, True, True, True, False, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, False, True, True, True, False, True, True, False, True, True, True, False, True, False, False, True, True, True, True, False, False, True, False, True, False, False, False, True, False, False, True, True, True, False, False, True, True, True, True, True, False, True, False, True, False, False, True, False, True, True, True, False, True, False, True, True, True, False, False, True, False, True, False, True, True, True, True, True, True, False, False, True, False, True, False, True, True, False, True, True, True, True, False, False, False, False, False, True, False, False, False, True, False, False, False, True, True, False, True, True, False, True, True, False, True, True, True, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, False, True, True, False, False, False, True, False, False, True, True, True, False, True, True, True, False, True, False, False, True, True, True, True, False, False, False, True, False, False, False, False, True, True, True, True, False, True, False, False, True, True, True, True, False, False, False, False, False, True, True, True, True, True, False, False, True, False, False, False, False, True, False, True, True, True, False, True, False, True, False, True, False, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, False, False, True, False, False, True, False, True, True, False, False, False, False, True, True, False, True, True, True, False, True, True, True, False, False, False, False, True, True, False, True, True, True, True, False, False, True, False, True, True, False, True, True, False, True, True, True, False, False, True, False, False, True, True, True, True, False, True, True, True, False, False, True, True, False, True, True, False, False, True, True, False, True, False, True, True, True, False, True, False, False, False, True, True, False, False, False, True, True, True, False, True, False, True, False, True, False, True, True, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True, True, False, True, True, False, False, True, True, False, True, True, True, True, False, True, False, True, False, True, True, False, False, True, False, True, False, False, False, True, False, False, True, True, False, True, True, True, True, True, False, True, False, False, True, True, False, True, False, True, True, False, True, False, False, False, True, False, False, True, True, True, False, False, True, True, True, True, True, False, False, True, False, False, False, True, False, True, False, True, False, False, True, True, True, True, False, True, False, True, True, False, False, True, True, True, True, False, True, True, False, False, True, False, True, False, True, True, True, True, False, False, True, True, False, False, True, True, True, False, False, False, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, False, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, False, False, True, False, True, False, True, False, False, True, True, False, True, False, False, True, True, True, False, True, True, False, False, True, True, False, False, True, True, True, False, True, True, True, False, True, False, False, True, True, True, True, False, True, True, False, False, True, False, True, False, True, True, True, False, False, True, True, True, False, False, True, False, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, True, True, True, False, True, False, False, False, False, False, False, True, False, True, True, True, False, False, True, True, True, True, False, False, True, False, True, True, True, True, False, True, False, True, True, False, True, False, False, False, False, True, True, True, False, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, False, True, True, False, True, True, False, False, False, True, False, False, True, False, True, False, True, False, True, False, True, False, True, False, False, False, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, False, True, True, False, True, True, True, True, True, True, True, False, False, True, True, True, False, False, True, True, True, True, True, False, False, True, False, False, True, True, False, False, True, False, False, True, True, True, True, False, True, True, True, False, True, True, False, True, True, False, True, True, False, False, True, False, True, True, True, False, True, False, False, False, False, True, True, True, True, True, True, False, False, False, True, False, False, True, True, True, False, True, True, True, True, True, False, False, True, True, True, True, False, True, True, True, True, False, True, False, True, True, False, True, True, True, True, True, False, True, False, True, False, False, False, True, True, True, True, False, True, True, False, True, False, True, True, False, True, True, True, True, True, True, False, True, False, True, False, False, False, False, True, True, True, False, True, True, True, False, True, True, False, False, False, True, True, True, False, False, True, True, False, True, False, True, True, True, True, True, True, True, True, True, False, True, False, True, False, True, False, True, True, False, True, False, True, True, True, False, False, False, False, True, True, False, True, False, True, True, False, True, False, True, True, True, True, True, False, False, True, True, True, False, False, True, True, True, True, True, True, False, True, False, True, True, True, False, False, True, True, False, True, True, True, True, False, False, True, False, True, True, True, False, False, True, False, True, True, True, False, True, False, True, True, True, False, False, False, True, False, True, True, False, True, True, True, False, True, True, True, True, True, False, False, True, True, True, True, True, True, False, False, True, True, True, True, False, False, False, True, True, False, True, True, False, True, False, False, True, True, False, False, False, True, False, True, True, True, True, True, False, False, False, False, True, False, True, True, True, True, True, True, True, False, False, True, False, False, True, True, True, False, True, True, True, True, True, False, True, True, True, True, False, False, True, False, True, True, False, True, False, True, False, False, False, False, True, False, False, False, True, False, True, False, True, True, True, True, True, True, True, False, True, True, False, False, False, True, True, True, True, False, False, True, True, True, True, False, True, True, False, True, True, False, True, False, False, True, True, True, True, False, False, False, True, False, True, False, False, False, True, True, True, False, True, True, True, True, True, True, True, False, True, False, False, False, True, True, False, True, False, False, False, False, True, True, False, True, False, True, True, False, False, True, True, False, True, True, True, True, True, False, False, True, True, True, True, True, True, False, False, False, True, False, True, False, False, False, True, False, True, True, False, True, True, True, True, False, False, False, True, False, False, False, True, True, True, True, False, True, False, False, True, True, True, False, True, False, True, True, True, False, False, True, True, True, True, True, False, True, True, True, False, True, False, False, True, False, False, True, True, True, False, False, True, True, True, False, True, True, True, True, True, False, True, True, True, False, False, True, True, True, False, True, True, False, True, False, True, True, False, False, True, True, False, False, True, True, True, True, True, True, True, False, True, False, True, False, True, False, False, False, True, True, True, True, True, True, False, True, False, False, True, False, False, True, True, True, True, False, True, True, False, True, True, False, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, False, False, True, False, True, True, True, False, True, True, False, True, False, True, True, True, False, False, True, True, False, False, False, True, False, True, False, True, True, True, True, True, False, True, False, True, True, False, True, False, True, True, False, True, True, False, False, True, True, True, False, True, False, True, True, True, True, False, False, True, True, False, True, True, True, True, True, False, True, True, True, False, False, False, True, True, False, False, True, True, True, False, False, True, False, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, False, False, True, False, True, True, True, True, True, False, True, False, True, False, True, True, True, True, True, True, False, False, True, True, True, True, False, True, True, True, True, False, True, False, True, True, True, True, False, True, True, False, True, True, True, False, False, True, False, True, True, True, True, False, True, False, True, True, True, True, True, True, True, False, False, True, False, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, False, False, True, True, False, True, True, True, False, False, True, False, False, True, False, True, False, False, False, True, False, True, False, True, True, True, False, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, False, True, True, True, True, False, True, False, False, False, False, True, True, False, False, False, True, False, True, True, True, True, False, False, True, False, True, False, True, False, True, True, True, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True, True, False, True, False, True, False, True, True, False, True, False, False, True, True, True, False, True, False, True, False, True, True, True, True, True, False, True, True, True, True, False, False, True, False, False, True, True, True, True, True, True, True, False, False, False, True, True, False, True, True, True, True, False, True, False, True, False, False, True, True, True, True, True, True, False, False, False, False, False, False, True, True, True, True, True, False, True, True, True, True, True, False, False, True, True, True, True, True, True, False, True, True, False, False, True, True, True, False, False, True, False, True, True, True, True, True, False, False, True, True, True, True, False, False, False, False, True, True, True, True, True, False, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, False, True, False, True, True, True, False, True, False, False, True, True, True, True, True, False, False, False, True, False, False, False, True, True, False, False, False, True, True, True, True, False, True, False, True, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, False, False, True, True, True, False, True, True, False, True, True, True, True, True, False, False, True, True, True, False, True, False, False, False, False, True, False, True, False, True, True, False, False, False, True, True, True, False, False, True, True, True, False, True, True, False, True, True, True, False, False, True, False, True, False, False, False, False, True, False, True, False, False, True, False, True, True, False, False, True, True, True, True, False, True, False, False, True, True, False, False, False, False, True, False, True, True, False, False, False, True, True, True, True, False, False, False, False, True, False, False, True, True, True, False, False, True, False, True, True, True, True, True, True, False, True, False, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, False, False, False, False, True, True, True, False, False, False, True, False, False, True, True, True, True, True, True, False, True, True, True, False, False, True, True, True, True, True, True, False, False, True, False, True, True, False, False, False, True, False, False, True, True, False, True, True, False, False, True, True, True, True, False, True, False, True, True, True, True, False, False, False, True, True, False, True, False, False, True, False, True, False, True, True, False, False, True, False, True, False, True, True, True, True, True, False, False, False, True, False, False, True, False, True, True, True, True, False, True, True, True, False, True, False, True, True, True, True, False, True, False, False, False, True, True, True, True, True, False, True, False, True, True, True, False, True, True, True, False, False, True, False, True, False, True, False, True, True, False, True, False, True, True, True, True, True, True, True, False, True, True, False, False, True, False, True, False, False, True, False, False, True, True, True, False, False, False, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, False, True, True, True, True, False, True, False, True, False, True, True, True, True, True, True, True, True, True, False, True, True, False, False, True, True, True, True, False, False, False, False, True, True, True, False, True, True, False, True, True, False, True, True, True, True, False, True, True, False, False, True, True, True, True, True, False, False, True, True, False, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, False, False, True, False, True, True, True, True, False, False, True, True, False, False, True, True, False, True, True, False, True, False, True, False, True, True, True, False, True, True, False, True, False, True, False, False, True, True, False, False, True, False, False, True, False, True, False, True, False, False, True, True, True, False, True, True, False, True, True, True, True, True, True, False, True, True, False, True, True, False, True, True, False, True, False, True, False, False, True, True, True, False, True, True, True, True, True, False, False, False, True, True, False, False, True, True, False, False, True, False, True, True, True, True, False, True, False, False, True, True, True, True, True, True, False, True, True, False, True, False, True, True, True, False, False, True, True, False, False, True, True, False, True, True, False, True, True, False, False, True, False, True, False, True, True, True, False, True, False, True, False, False, False, True, True, True, False, True, False, True, True, True, False, False, True, True, True, False, False, False, False, True, True, True, False, False, True, False, True, False, True, True, True, False, True, False, True, True, False, True, True, False, True, True, False, True, False, True, True, True, False, False, False, True, False, False, True, True, True, True, True, False, True, False, True, True, False, True, True, True, True, True, True, True, False, True, True, False, False, True]\n"
          ]
        }
      ],
      "source": [
        "y_pred = predict(hof.items[0], X_test2)\n",
        "print(\"Predicted classes of the test set: \", y_pred)                            #check the predictions and printing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvilz5ApvV05"
      },
      "source": [
        "Save it in a .csv file and submit it in the Kaggle competition.\n",
        "\n",
        "The format is as follows:\n",
        "1. First column is the original `PassengerId` column in the test set;\n",
        "2. Second column is named `Transported` and contains the predictions (only 0's or 1's)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "fSfvrJERL0MK"
      },
      "outputs": [],
      "source": [
        "y_pred_temp=[]\n",
        "for each in y_pred:\n",
        "  y_pred_temp.append(str(each).upper())                                         #fix for converting true/false to TRUE/FALSE for kaggle\n",
        "y_pred=y_pred_temp"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hSorn9HVMLXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5OJr0ovMY24",
        "outputId": "12003b24-dadc-482b-850a-b44a33479532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'TRUE']\n"
          ]
        }
      ],
      "source": [
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "8ap20PzQz3aq"
      },
      "outputs": [],
      "source": [
        "df_id = df_test['PassengerId']\n",
        "df_class = pd.DataFrame(data=y_pred, columns = ['Transported'])\n",
        "df_pred = pd.concat([df_id, df_class], axis=1)\n",
        "\n",
        "df_pred.to_csv('predictions_'+str(hof.items[0].fitness.values[0])+'.csv', sep=',', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "NO49s6nysoo8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9f8e68a2-8c0c-4876-d3a1-066509dc74bd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1fb551cc-98c8-4cd5-95c9-60b628503beb\", \"predictions_0.22050000000000003.csv\", 51079)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('predictions_'+str(hof.items[0].fitness.values[0])+'.csv')       #download the predictions with fitness score in name"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
